<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[简单优雅的搭建个人博客]]></title>
    <url>%2F20190930%2F%E7%AE%80%E5%8D%95%E4%BC%98%E9%9B%85%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2.html</url>
    <content type="text"><![CDATA[前言啊啊啊~~~ ,经过差不多两天的持续摸索优化，个人博客算是初步完成了，现在自己看的效果还是非常不错的。这篇文章就是讲我怎么搭建一个这样的博客的。早在17年的时候就用hexo 结合github搭建过个人博客，但是那时候还太年轻，也没有维护，后面就废掉了。18年的时候又一时兴起搭建了一个。比17年的时候好看些，但是没有什么访问量，可能没有做seo 优化，也没有维护多长时间就放着了，前几天上去看，界面显示都还正常，就是内容太幼稚了。所以时隔一年，我胡汉三又回来了。痛下决心，把整体的博客都搭建好了，包含界面渲染，RSS,评论系统，站内搜索，seo 优化等等。现在让我们开始吧。博客传送门：coding:http://quellanan.coding.me/ github:https://quellanan.github.io/ 最终效果我们先来看看效果吧，这样对你们可能更有吸引力，更有动力搭建一个属于自己的bolg 啦。 主页面是这样的，包含首页、标签、分类、归档、关于、互动、搜索、还有右侧的主页。最喜欢标签这一页，可以看出整个网站对哪一类的文章写的比较多。 还可以通过标签找到对应的文章。还有就就是页脚的网站统计，页面访问人数和访问量的统计。已经整个站点博文的字数。这些相信都是自建博主们最关心的。我也是最关心这部分哈哈，毕竟访问量和人数上去了就有持续更新的动力啦。打赏功能，已经版权申明，还有侧边的文章目录也是超赞的。 评论功能，这个评论也是很给力的吧，增加了博主和读者之间的交流。和评论类似还有一个，就是网站右下角那个类似微信图标的那个，那个也是可以直接和博主沟通的哟，不赖吧。这些只是网站的一部分功能，其他的就不说了，开始动手吧 环境准备 安装git：https://git-scm.com/book/zh/v2/起步-安装-Git安装git 之后又配置用户名和邮箱，和github 一致 1234#全局配置用户名git config --global user.name "nameVal"#全局配置邮箱git config --global user.email "eamil@qq.com" 安装node.js：https://nodejs.org/en/这两个不管你linux 还是windows 都非常好安装，网上关键字搜索一下，有官方教程。 注册github登录账号：https://github.com/创建好和用户名一样的项目 注册coding登录账号：https://coding.net/login也是一样的，创建一个和名称相同的项目。这里说一下为什么要用coding，其实不用也可以，coding 和github 的作用一样的，都是作为pages 以及使用他们的域名。不同的是github 是国外的，而coding 是国内的。github搭建的博客不容易被百度检索到，而coding 可以。大家可以根据个人喜好选择吧。这里我是两个都用了，反正就多一条配置。 配置秘钥12$ cd ~$ ssh-keygen -t rsa -C "your_email@youremail.com" 将生成的秘钥配置到github 和coding 上就好了 安装hexo安装好git 和node 之后，安装hexo 就很方便1npm install hexo-cli -g 随后我们创建一个blog 文件夹，用来存放我们的blog.123cd bloghexo initnpm install 这样基本的框架就已经搭建好了，可以启动看下效果1234hexo clean //清缓存hexo g //编译hexo s //本地运行hexo d // 上传到github 或者coding 主题选择在搭建好框架之后，现在当然是找一个自己喜欢的主题啦，我个人比较喜欢next ,然后就在网上找了一个next 主题，功能配置基本都有了，我就是参照这个大佬的配置过来的。 配置：https://github.com/ipyker/hexo-next-theme 将这位大佬的主题下载下来后，放到我们自己的主题中去就好了。常见的修改按照这位大佬提示的修改就可以。 保存源码好了，主题和框架都有了，那接下来其实写博客发布就好了，其实前面的我前两年走到这里了，所以前面没有很细的讲。但是有一些基础的人应该都可以做到，如果不行，可以通过我提到的关键字搜索也可以在网上找到详细的教程。为什么这次又要重新搭建，因为之前没有保存源码，导致github 上只存了pages 的代码。没有保存源码，所以如果源码丢了就得重新搭建了。所以这次学聪明了知道保存源码，不管是换电脑还是什么的，做号备份就不怕了。我这里讲源码保存在github 上，我们在github项目项目上创建一个分支 save，用来保存源码。master 分支用来pages页面展示。将创建的save 分支设置为默认分支。 然后在本地clone 项目。进入项目123git add .git commit -m "your description"git push origin save 我们 _config.yml 配置是提交到 master 分支 123456deploy: type: git repository: github: git@github.com:QuellanAn/QuellanAn.github.io.git coding: git@git.dev.tencent.com:quellanan/QuellanAn.git branch: master 现在开始，之后的操作就简单了。想要编译发布就 123hexo clean hexo ghexo d 保存到github就12345git pull git add .git statusgit commint -m "description"git push origin save 我博文的源码地址：https://github.com/QuellanAn/QuellanAn.github.io这些都是我已经配置好了，你们可以直接clone下来，进入 blog 文件夹然后进行运行修改就可以了。所以我前面都讲的比较简单。 SEO现在我们博客已经建好了，我们要新增博客的话在source / _posts 目录下增加就好了。 但是我们现在面临的一个问题是，我们的博客没有访问量怎么办，不能通过谷歌搜索和百度搜索搜索到，而是需要直接通过输入准确的网址进行访问，这样肯定是不利于我们增加博客浏览量的。所以我们需要将我们的网址添加到百度和谷歌搜索中。 谷歌：https://search.google.com/search-console将下载的html 放到public 文件夹下。然后12hexo ghexo d 发布到我们的网站上。然后进行验证就可以验证通过。这个验证之后，我们再提交站点地图。站点地图我都配置好了，如果你们用我的模版的话，直接在网站站点地图提交就好了 这样过段时间谷歌就能搜索到你的博客啦。 百度提交站点：https://ziyuan.baidu.com/site/index添加网站，验证方法和google 是一样的，都用html 文件验证就好了验证完成之后，点击Robots,检测并更新。我的模版里面已经配置好了。可以直接检测到。 虽然我做了这些，但是好像百度还没有搜录，还得再等两天再看看。 番外好了，到此为止，个人博客搭建就到这这里了，大家如果也想要搭建一个自己的博客，可以把文中说的准备工作做好，然后自己下载我的源码来用，把信息修改成自己的就好了。有什么不懂了可以及时加我微信沟通。因为我模版里，我的博文原稿都在里面，所以各位用的时候记得删掉，或者记得标记为转载谢谢❤ 可能讲的内容不够详细，没有细节没有讲到，对小白不太友好，但是考虑到其实网上有很多详细的教程，我这里就把我认为重要的讲了出来，希望对大家有帮助。 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>个人博客</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UE激活（亲测有效，通过注册机激活）]]></title>
    <url>%2F20190930%2FUE%E6%BF%80%E6%B4%BB%EF%BC%88%E4%BA%B2%E6%B5%8B%E6%9C%89%E6%95%88%EF%BC%8C%E9%80%9A%E8%BF%87%E6%B3%A8%E5%86%8C%E6%9C%BA%E6%BF%80%E6%B4%BB%EF%BC%89.html</url>
    <content type="text"><![CDATA[前言之前一直用的是SublimeText系列，也感觉很好用的，在文本编辑上UE 和 SublimeText感觉差不多，用起来都比较舒服，但是我看中的UE一个强大的功能，可以在编辑时切换行模式和列模式。同时操作多列，虽然很少用到，但是真用的时候就方便很多了。另外UE也有一系列的产品，比如UC就是一个比较的好的比较工具。好了说了这么多开始激活吧。 准备工作：1.下载好UE(官网下载即可，https://www.ultraedit.com/)2.下载注册机，我的（https://pan.baidu.com/s/1I4uEGxL5s3P3iB2nVvXBEQ 提取密码：8myi）3.断网。 激活接下打开UE ,点击”输入许可证秘钥”。然后出来下面界面，需要输入许可证和密码，这个随便输入就可以了，但是最好不要输入字符和字母。输入数字就好了点击激活会提示没有网络，然后就选择脱机激活点击脱机激活，弹出一下界面：界面上回有上个用户码，双击运行注册机，出现一下界面，将两个用户码填入对应位置，点击Generate,会生成对应的验证码将验证码输入到UEd激活界面。点击激活，就可以激活成功啦，然后可以看一下设置，发现已经激活成功了，可以愉快的玩耍了 番外我使用了一段时间后又提示我的许可证到期了，让我重新激活，我一想不得劲呀这。然后我就在激活以后对这个软件做了禁网操作。我想这样它不会总让我激活吧哈哈，佩服自己的灵机一动。怎么给单个软件禁网，不好意思我用的是 腾讯电脑管家-工具箱-上网-流量监控。找到UE，禁用网络就好了。 当然我想360卫士、金山卫士都有类似的禁用网络的功能吧，自己找找，网上还有大佬说通过防火墙-高级设置对应用程序进行禁网，不会弄哈哈。 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>UE</tag>
        <tag>激活</tag>
        <tag>注册码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何优雅实现属性的动态注入]]></title>
    <url>%2F20190929%2F%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%AE%9E%E7%8E%B0%E5%B1%9E%E6%80%A7%E7%9A%84%E5%8A%A8%E6%80%81%E6%B3%A8%E5%85%A5.html</url>
    <content type="text"><![CDATA[前言这是在实际开发项目中遇到的一个问题。从数据库查询返回的 List&lt; Map&lt; String, Object>> 的集合。并且返回的列名是中文的，项目也没有使用mybatis 直接使用的jdbcTemplate. 并且字段还超级多，这样将数据转换的时候如果一个一个的注入就会让代码臭长臭长的，所以才有了动态注入。我这里我整个思路都贴出来。 实例类Entry我们先建一个entry类。用于对象存储。我这里 创建一个BaseDateBean 的类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374@Setter@Getterpublic class BaseDateBean &#123; private String startTime; private String operator; private String code; private String testNumber; private String iphoneCardCode; private String sampleNumber; private String sampleTime; private String callNumber; private String callStatus; private String downInstantaneousSpeedCard; private String upInstantaneousSpeedCard; private String ssid; private String bssid; private String encryptType; private String intranetIp; private String externalIp; private String rssi; private String WIFIFrequency; private String WIFIChannel; private String baiduLongitude; private String baiduLatitude; private String originalLongitude; private String originalLatitude; private String positioningPrecision; private String positioningType; private String businessType; private String networkType; private String speedType; private String tac; private String eci; private String mnc; private String mcc; private String rsrq; private String earfcnDl; private String earfcnUl; private String frequencyDl; private String band; private String sinr; private String cdmaRxlev; private String evdoRxlev; private String earfcn; private String psc; private String uarfcn; private String rscp; private String rsrp; private String imsi; private String imei; private String lac; private String ci; private String signalStrength; private String snr; private String pci; private String nid; private String bid; private String sid; private String cdmaDbm; private String cdmaEcio; private String evdoDbm; private String evdoEcio; private String evdoSnr; private String arfcn; private String frequencyUl; private String bsic; private String rxlev; private String averageSpeed; private String updatedLongitude; private String updatedLatitude; private String averageUpstreamRate; private String averageDownstreamRate;&#125; 可以看到在实际项目中属性还是很多的，我这个还只是初版的，所以如果一个一个的set注入就很low了。 创建map映射在创建好实体类后，还得创建一个静态的map 集合，将数据库的列名和我们实体类的属性名做一个一一对应。这里创建的这个map 集合是我个人愚见。没有想到更好的办法就先这样处理的。我们创建一个BaseDataMap类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class BaseDataMap&#123; private BaseDataMap()&#123;&#125; public static final Map&lt;String,String&gt; cnEnMap=new HashMap&lt;&gt;(); static&#123; cnEnMap.put("测试开始时间","startTime"); cnEnMap.put("运营商","operator"); cnEnMap.put("编号","code"); cnEnMap.put("测试编号","testNumber"); cnEnMap.put("手机卡编号","iphoneCardCode"); cnEnMap.put("采样编号","sampleNumber"); cnEnMap.put("采样时间","sampleTime"); cnEnMap.put("呼叫编号","callNumber"); cnEnMap.put("呼叫状态","callStatus"); cnEnMap.put("下行瞬时速度","downInstantaneousSpeedCard"); cnEnMap.put("上行瞬时速度","upInstantaneousSpeedCard"); cnEnMap.put("SSID","ssid"); cnEnMap.put("BSSID","bssid"); cnEnMap.put("加密类型","encryptType"); cnEnMap.put("内网IP","intranetIp"); cnEnMap.put("外网IP","externalIp"); cnEnMap.put("RSSI","rssi"); cnEnMap.put("WIFI频率","WIFIFrequency"); cnEnMap.put("WIFI信道","WIFIChannel"); cnEnMap.put("百度经度","baiduLongitude"); cnEnMap.put("百度纬度","baiduLatitude"); cnEnMap.put("原始经度","originalLongitude"); cnEnMap.put("原始纬度","originalLatitude"); cnEnMap.put("定位精度","positioningPrecision"); cnEnMap.put("定位类型","positioningType"); cnEnMap.put("数据业务类型","businessType"); cnEnMap.put("网络类型","networkType"); cnEnMap.put("速度类型","speedType"); cnEnMap.put("TAC","tac"); cnEnMap.put("ECI","eci"); cnEnMap.put("MNC","mnc"); cnEnMap.put("MCC","mcc"); cnEnMap.put("RSRQ","rsrq"); cnEnMap.put("EARFCN DL","earfcnDl"); cnEnMap.put("EARFCN UL","earfcnUl"); cnEnMap.put("FREQUENCY DL","frequencyDl"); cnEnMap.put("BAND","band"); cnEnMap.put("SINR","sinr"); cnEnMap.put("CDMA RXLEV","cdmaRxlev"); cnEnMap.put("EVDO RXLEV","evdoRxlev"); cnEnMap.put("EARFCN","earfcn"); cnEnMap.put("PSC","psc"); cnEnMap.put("UARFCN","uarfcn"); cnEnMap.put("RSCP","rscp"); cnEnMap.put("RSRP","rsrp"); cnEnMap.put("IMSI","imsi"); cnEnMap.put("IMEI","imei"); cnEnMap.put("LAC","lac"); cnEnMap.put("CI","ci"); cnEnMap.put("信号强度","signalStrength"); cnEnMap.put("SNR","snr"); cnEnMap.put("PCI","pci"); cnEnMap.put("NID","nid"); cnEnMap.put("BID","bid"); cnEnMap.put("SID","sid"); cnEnMap.put("CDMA DBM","cdmaDbm"); cnEnMap.put("CDMA ECIO","cdmaEcio"); cnEnMap.put("EVDO DBM","evdoDbm"); cnEnMap.put("EVDO ECIO","evdoEcio"); cnEnMap.put("EVDO SNR","evdoSnr"); cnEnMap.put("ARFCN","arfcn"); cnEnMap.put("FREQUENCY UL","frequencyUl"); cnEnMap.put("BSIC","bsic"); cnEnMap.put("RXLEV","rxlev"); cnEnMap.put("速率","averageSpeed"); cnEnMap.put("更正后经度","updatedLongitude"); cnEnMap.put("更正后纬度","updatedLatitude"); cnEnMap.put("上行平均速率","averageUpstreamRate"); cnEnMap.put("下行平均速率","averageDownstreamRate"); &#125;&#125; 可以看到就是一个动态的map。 映射类接下来就是核心代码啦。我们创建一个ReflectHelper类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Slf4jpublic class ReflectHelper &#123; private Class cls; /** * 传过来的对象 */ private Object obj; private Hashtable&lt;String, Method&gt; getMethods = null; private Hashtable&lt;String, Method&gt; setMethods = null; public ReflectHelper(Object o) &#123; obj = o; initMethods(); &#125; public void initMethods() &#123; getMethods = new Hashtable&lt;&gt;(); setMethods = new Hashtable&lt;&gt;(); cls = obj.getClass(); Method[] methods = cls.getMethods(); // 定义正则表达式，从方法中过滤出getter / setter 函数. String gs = "get(\\w )"; Pattern getM = Pattern.compile(gs); String ss = "set(\\w )"; Pattern setM = Pattern.compile(ss); // 把方法中的"set" 或者 "get" 去掉,$1匹配第一个 String rapl = "$1"; String param; for (int i = 0; i &lt; methods.length; i) &#123; Method m = methods[i]; String methodName = m.getName(); if (Pattern.matches(gs, methodName)) &#123; param = getM.matcher(methodName).replaceAll(rapl).toLowerCase(); getMethods.put(param, m); &#125; else if (Pattern.matches(ss, methodName)) &#123; param = setM.matcher(methodName).replaceAll(rapl).toLowerCase(); setMethods.put(param, m); &#125; &#125; &#125; public boolean setMethodValue(String property,Object object) &#123; Method m = setMethods.get(property.toLowerCase()); if (m != null) &#123; try &#123; // 调用目标类的setter函数 m.invoke(obj, object); return true; &#125; catch (Exception ex) &#123; ex.printStackTrace(); return false; &#125; &#125; return false; &#125;&#125; 上面代码可以看到其实也就两个方法setMethodValue 和initMethods 。initMethods 方法是在实例化 ReflectHelper 这个类的时候执行的，主要的工作就是找到我们需要动态注入实例类的get 和set 方法。而setMethodValue 方法就是给这个属性赋值的。 实现方法 现在准备工作做好了，怎么使用呢? 1234567891011121314151617181920212223private List&lt;BaseDateBean&gt; getBaseDateBean(List&lt;Map&lt;String, Object&gt;&gt; mapList)&#123; List&lt;BaseDateBean&gt; list=new ArrayList&lt;&gt;(); if(mapList==null||mapList.isEmpty())&#123; return list; &#125; BaseDateBean baseDateBean; for(Map&lt;String, Object&gt; map:mapList)&#123; baseDateBean=new BaseDateBean(); for(Map.Entry&lt;String, Object&gt; entry : map.entrySet())&#123; String mapKey = entry.getKey(); log.info(mapKey); ReflectHelper reflectHelper = new ReflectHelper(baseDateBean); log.info(BaseDataMap.cnEnMap.get(mapKey)); String value=entry.getValue()==null?ConstantPool.SEPARATORNULL:entry.getValue().toString(); log.info(value); if(entry.getValue()!=null)&#123; reflectHelper.setMethodValue(BaseDataMap.cnEnMap.get(mapKey),String.valueOf(entry.getValue())); &#125; &#125; list.add(baseDateBean); &#125; return list; &#125; 遍历list 集合中的map，动态的将属性值注入到实体类中。 番外 我这里是适合我业务开发设计的思路，给大家借鉴参考。 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>动态注入</tag>
        <tag>映射</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、springBoot优雅的创建定时任务]]></title>
    <url>%2F20190926%2F%E5%9B%9B%E3%80%81springBoot%20%E4%BC%98%E9%9B%85%E7%9A%84%E5%88%9B%E5%BB%BA%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1.html</url>
    <content type="text"><![CDATA[前言好几天没写了，工作有点忙，最近工作刚好做一个定时任务统计的，所以就将springboot 如何创建定时任务整理了一下。总的来说，springboot创建定时任务是非常简单的，不用像spring 或者springmvc 需要在xml 文件中配置，在项目启动的时候加载。spring boot 使用注解的方式就可以完全支持定时任务。不过基础注解的话，可能有的需求定时任务的时间会经常变动，注解就不好修改，每次都得重新编译，所以想将定时时间存在数据库，然后项目读取数据库执行定时任务，所以就有了基于接口的定时任务。下面就分基于注解和基于接口详细讲解。 基于注解pom.xml 文件不用修改，我们原本的项目就支持，其实定时器是springboot框架自带的，不用引入什么依赖。我们直接创建一个autotask 包，创建一个AutoTask类。123456789@EnableScheduling@Component@Slf4jpublic class AutoTask &#123; @Scheduled(cron="*/6 * * * * ?") private void process()&#123; log.info("autoTask "); &#125;&#125; 这样一个定时器就创建啦，在项目启动后，会每隔6s 打印“autoTask”的日志。是不是很简单。主要用到的两个注解就是@EnableScheduling 和 @Scheduled。注解@EnableScheduling 就是开启定时任务的。哪个类的中的方法想要定期执行，就在这个类上加入这个注解。当然这个这个注解也可以加在启动类上。加在启动类上表示项目中所有的类都可以创建定时任务。 @Scheduled 注解就是我们常见的定时器啦，后面的cron 就是定时任务表达式。在方法上注解，表示这个方法定期执行。不过@Scheduled 可以进行两种配置，我们熟悉的cron ,还有一种是fixedRate。比如fixedRate=6000 表示方法每6秒钟执行一次。我们来启动项目看一下，可以看到两个方法都在定期执行。 基于接口上面可以看到springboot 基于注解是非常方便的。但是对于频繁变动或者一个项目中有很多的定时器那就不方便管理了。所以统一将定时器信息存放在数据库中。12345678DROP TABLE IF EXISTS `scheduled`;CREATE TABLE `scheduled` ( `cron_id` varchar(30) NOT NULL PRIMARY KEY, `cron_name` varchar(30) NULL, `cron` varchar(30) NOT NULL);INSERT INTO `scheduled` VALUES ('1','定时器任务一','0/6 * * * * ?'); 在dao 层mapper1包下创建一个CronMapper接口，很简单的就获取cron12345public interface CronMapper &#123; @Select("select cron from scheduled where cron_id = #&#123;id&#125;") public String getCron(int id);&#125; 这里我们就不写service 层了。直接在autotask 包下创建一个AutoTaskFromDB类12345678910111213141516171819202122232425@Slf4j@Componentpublic class AutoTaskFromDB implements SchedulingConfigurer &#123; @Autowired protected CronMapper cronMapper; @Override public void configureTasks(ScheduledTaskRegistrar scheduledTaskRegistrar) &#123; scheduledTaskRegistrar.addTriggerTask(() -&gt; process(), triggerContext -&gt; &#123; String cron = cronMapper.getCron(1); if (cron.isEmpty()) &#123; log.info("cron 为空"); &#125; return new CronTrigger(cron).nextExecutionTime(triggerContext); &#125; ); &#125; private void process()&#123; log.info("formDB "); &#125;&#125; 可以看到也很简单，就是实现SchedulingConfigurer 这个吧接口，addTriggerTask（）是添加一个定时器。process（）方法是我们需要定时执行的方法体。CronTrigger(cron).nextExecutionTime(triggerContext) 就是从数据库读取的cron 创建定时器。 这个类我没有加上@EnableScheduling 注解，因为我在启动类上加上了，如果你们启动类上没有加，这里记得加上。 测试一下;下图可以看到三个定时任务都执行了，fromDB 是从数据库读取的。 croncron 用法网上有很多，也没有什么讲的这里就附带记录下 结构cron表达式是一个字符串，分为6或7个域，每两个域之间用空格分隔，其语法格式为：”秒域 分域 时域 日域 月域 周域 年域” 取值范围 域名 可取值 可取符号（仅列部分常用） 秒域 0~59的整数 * - , / 分域 0~59的整数 * - , / 时域 0~23的整数 * - , / 日域 1~31的整数 * - , / ? L 月域 1~12的整数或JAN~DEC * - , / 周域 1~7的整数或SUN~SAT * - , / ? L # 年域 1970~2099的整数 * - , / 常例 表达式 意义 每隔5秒钟执行一次 */5 * * * * ? 每隔1分钟执行一次 0 * /1 * * * ? 每天1点执行一次 0 0 1 * * ? 每天23点55分执行一次 0 55 23 * * ？ 每月最后一天23点执行一次 0 0 23 L * ？ 每周六8点执行一次 0 0 8 ? * L 每月最后一个周五，每隔2小时执行一次 0 0 */2 ? * 6L 每月的第三个星期五上午10:15执行一次 0 15 10 ? * 5#3 在每天下午2点到下午2:05期间的每1分钟执行 0 0-5 14 * * ? 表示周一到周五每天上午10:15执行 0 15 10 ? * 2-6 每个月的最后一个星期五上午10:15执行 0 15 10 ? * 6L 每天上午10点，下午2点，4点执行一次 0 0 10,14,16 * * ? 朝九晚五工作时间内每半小时执行一次 0 0/30 9-17 ? 每个星期三中午12点执行一次 0 0 12 ? * 4 每年三月的星期三的下午2:10和2:44各执行一次 0 10,44 14 ? 3 4 每月的第三个星期五上午10:15执行一次 0 15 10 ? * 6#3 每月一日凌晨2点30执行一次 0 30 2 1 * ? 每分钟的第10秒与第20秒都会执行 10,20 * * * * ? 每月的第2个星期的周5，凌晨执行 0 0 0 ? * 6#2 番外本来这个知识点不应该放在这里讲的，但是不多，顺带写了，刚好也能做定时器。我们项目中往往有一些需求需要在项目启动的时候就执行，那这个我们怎么实现了。其实spring boot 使用起来也非常简单，只用实现 ApplicationRunner 就好了。我们在autotask 包下创建一个AutoTaskFromSpringRunner类 12345678910111213@Slf4j@Componentpublic class AutoTaskFromSpringRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; process(); &#125; private void process()&#123; log.info(" run ApplicationArguments"); &#125;&#125; 启动项目看一下，可以发现这个会在项目启动后执行，但是只会执行一次。 那这个怎么用来做定时器呢？当然是结合线程来做啦，但是这个方法其实不建议，b毕竟线程很容易出问题，但是提供一种思路： 12345678910111213141516171819202122232425@Slf4j@Componentpublic class AutoTaskFromSpringRunner implements ApplicationRunner &#123; @Override public void run(ApplicationArguments args) throws Exception &#123; process(); new Thread(() -&gt; &#123; while (true) &#123; process2(); try &#123; Thread.sleep(6000); &#125; catch (InterruptedException e) &#123; log.error("&#123;&#125;",e); &#125; &#125; &#125;).start(); &#125; private void process()&#123; log.info(" run ApplicationArguments"); &#125; private void process2()&#123; log.info("线程定时器"); &#125;&#125; 启动项目看下，发现也是可以起到定时器的作用的。 好了，就说这么多啦，今天项目的代码也同步到github 上啦。github地址：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、SpringBoot 整合mybatis 多数据源以及分库分表]]></title>
    <url>%2F20190921%2F%E4%B8%89%E3%80%81SpringBoot%20%E6%95%B4%E5%90%88mybatis%20%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E4%BB%A5%E5%8F%8A%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8.html</url>
    <content type="text"><![CDATA[前言说实话，这章本来不打算讲的，因为配置多数据源的网上有很多类似的教程。但是最近因为项目要用到分库分表，所以让我研究一下看怎么实现。我想着上一篇博客讲了多环境的配置，不同的环境调用不同的数据库，那接下来就将一个环境用到多个库也就讲了。所以才有了这篇文章。我们先来看一下今天项目的项目结构，在上篇博客的基础上进行了一定的增改，主要是增加了一个 config 文件，在dao 中分了两个子包mapper1 和mapper2 将原先的UserMapper 移入到了 mapper1 中。好了，开始正文 多数据源配置背景在这之前，还是先说一下为什么会存在多数据源。如果项目小的话，当然是所有的数据以及逻辑处理都操作同一个库。但是当业务量大的话，就会考虑到分库了。比我会将也日志入库数据存放到单独的数据库。或者用户权限信息单独的一个库存放。这种如果只是简单的分库，一个项目中就用到2~4 个数据库的话，这种多数据源配置就有意义啦。在配置文件中配置好这几个数据源，都有唯一标识。项目在启动加载的时候都进行初始化，然后在调用的时候，想用哪个库就哪个数据源的连接实例就好了。 如果不整合 mybatis 的话，直接使用使用spring 自带的jdbcTemplate ，那配置多数据源，以及使用都比较简单，但是整合 mybatis 的话，就相对复杂点。我们一步一步来将讲解。 修改配置文件打开application-dev.yml 文件，添加数据源。12345678910111213141516171819202122#开发环境spring: # 数据源配置 datasource: one: driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.252.53:3306/zlflovemm?characterEncoding=utf-8&amp;useSSL=false&amp;zeroDateTimeBehavior=CONVERT_TO_NULL username: root password: 123456 max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 two: driver-class-name: com.mysql.jdbc.Driver jdbc-url: jdbc:mysql://192.168.252.53:3306/zlfdb?characterEncoding=utf-8&amp;useSSL=false&amp;zeroDateTimeBehavior=CONVERT_TO_NULL username: root password: 123456 max-idle: 10 max-wait: 10000 min-idle: 5 initial-size: 5 这里需要注意的是如果使用的是springboot 2.0 以上的，那么注意是 driver-class-name 和 jdbc-url 而不是driverClassName和url.这里是一个坑，提醒大家一下。 配置数据源接下来就需要我们手动的加载什么什么数据源了，我们在config中创建 DataSourcesConfig 类1234567891011121314151617@Configurationpublic class DataSourcesConfig &#123; @Bean(name="dbOne") @ConfigurationProperties(prefix = "spring.datasource.one") @Primary DataSource dbOne()&#123; return DataSourceBuilder.create().build(); &#125; @Bean(name="dbTwo") @ConfigurationProperties(prefix = "spring.datasource.two") DataSource dbTwo()&#123; return DataSourceBuilder.create().build(); &#125;&#125; 这里定义了两个数据源的DataSource。分别是我们在配置文件中配置的one 和two 。注解@Primary 表示默认使用的数据源。 MyBatisConfigOne 类12345678910111213141516171819@Configuration@MapperScan(basePackages = "com.quellan.zlflovemm.dao.mapper1",sqlSessionFactoryRef = "sqlSessionFactory1",sqlSessionTemplateRef = "sqlSessionTemplate1")public class MyBatisConfigOne &#123; @Resource(name = "dbOne") DataSource dbOne; @Bean @Primary SqlSessionFactory sqlSessionFactory1()throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dbOne); return bean.getObject(); &#125; @Bean @Primary SqlSessionTemplate sqlSessionTemplate1() throws Exception&#123; return new SqlSessionTemplate(sqlSessionFactory1()); &#125;&#125; MyBatisConfigTwo 类1234567891011121314151617@Configuration@MapperScan(basePackages = "com.quellan.zlflovemm.dao.mapper2",sqlSessionFactoryRef = "sqlSessionFactory2",sqlSessionTemplateRef = "sqlSessionTemplate2")public class MyBatisConfigTwo &#123; @Resource(name = "dbTwo") DataSource dbTwo; @Bean SqlSessionFactory sqlSessionFactory2()throws Exception &#123; SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(dbTwo); return bean.getObject(); &#125; @Bean SqlSessionTemplate sqlSessionTemplate2()throws Exception &#123; return new SqlSessionTemplate(sqlSessionFactory2()); &#125;&#125; 注意连个文件的区别： dao 层在dao 层创建了两个包mapper1 和mapper2 .包里面的UserMapper类的内容是完全一样，放在不同的包中只是区分使用哪个数据源。和昨天是一样的。123456789101112public interface UserMapper &#123; @Select("select id,username as userName,password,email,role_code as roleCode,gmt_create as gmtCreate,gmt_update as gmtUpdate,nickname as nickName,user_create as userCreate from sys_user") List&lt;UserEntry&gt; findUserList(); @Insert(&#123;"insert into sys_user(username,password,email) values('$&#123;user.userName&#125;','$&#123;user.password&#125;','$&#123;user.email&#125;')"&#125;) int add(@Param("user") UserEntry user); @Delete("delete from sys_user where id = #&#123;id&#125;") int delete(int id);&#125; service 层UserService接口1234567891011121314public interface UserService &#123; List&lt;UserEntry&gt; findUserList(); int addUser(String userName,String password,String email); int deleteUser(int id); List&lt;UserEntry&gt; findUserList2(); int addUser2(String userName,String password,String email); int deleteUser2(int id);&#125; UserServiceImpl类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired protected UserMapper userMapper; @Autowired protected UserMapper2 userMapper2; @Override public List&lt;UserEntry&gt; findUserList() &#123; return userMapper.findUserList(); &#125; @Override public int addUser(String userName, String password, String email) &#123; UserEntry user=new UserEntry(); user.setUserName(userName); user.setPassword(password); user.setEmail(email); return userMapper.add(user); &#125; @Override public int deleteUser(int id) &#123; return userMapper.delete(id); &#125; @Override public List&lt;UserEntry&gt; findUserList2() &#123; return userMapper2.findUserList(); &#125; @Override public int addUser2(String userName, String password, String email) &#123; UserEntry user=new UserEntry(); user.setUserName(userName); user.setPassword(password); user.setEmail(email); return userMapper2.add(user); &#125; @Override public int deleteUser2(int id) &#123; return userMapper2.delete(id); &#125;&#125; controller 层userController12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Slf4j@RestController@RequestMapping("/user")public class UserController &#123; @Autowired private UserService userService; @RequestMapping(value = "/list",method = RequestMethod.GET) public List&lt;UserEntry&gt; findUserList()&#123; return userService.findUserList(); &#125; @RequestMapping(value = "/add",method = RequestMethod.GET) public String addUser(@RequestParam(value = "userName")String uaserName,@RequestParam(value = "password")String password,@RequestParam(value = "email")String email)&#123; int falg=userService.addUser(uaserName,password,email); if(falg&gt;0)&#123; return "success"; &#125; return "error"; &#125; @RequestMapping(value = "/delete",method = RequestMethod.GET) public String deleteUser(@RequestParam(value = "id")int id)&#123; if(userService.deleteUser(id)&gt;0)&#123; return "success"; &#125; return "error"; &#125; @RequestMapping(value = "/list2",method = RequestMethod.GET) public List&lt;UserEntry&gt; findUserList2()&#123; return userService.findUserList2(); &#125; @RequestMapping(value = "/add2",method = RequestMethod.GET) public String addUser2(@RequestParam(value = "userName")String uaserName,@RequestParam(value = "password")String password,@RequestParam(value = "email")String email)&#123; int falg= userService.addUser2(uaserName,password,email); if(falg&gt;0)&#123; return "success"; &#125; return "error"; &#125; @RequestMapping(value = "/delete2",method = RequestMethod.GET) public String deleteUser2(@RequestParam(value = "id")int id)&#123; if(userService.deleteUser2(id)&gt;0)&#123; return "success"; &#125; return "error"; &#125;&#125; 测试可以看到是从不同的库中调出来的。这样就说明我们springboot配置多数据源整合mybatis 已经成功了。其实最主要就是config 包下的那三个配置类。其他的都是常见的业务逻辑，所以后面我就没有怎么讲了，代码会同步到github 上，想要实践的可以拿源码下来实践。 到此我们springboot整合mybatis 多数据源已经配置好了，但是我们配置下来可以发现，我们如果想要配置几个数据源就得在 dao 层创建多少个子包用来区分。那如果我们数据量足够大，要分库分表而不是几个库呢？ 分库分表背景其实分库分表和多数据源是一样的，只不过是数据源更多了，多到在配置中配置所有的连接显得很臃肿，所以不得不另觅它法。分库分表就是 在项目中配置连接主库的连接，从主库中读取各个分库的连接，然后进行动态的加载，那个接口想调用那个分库就加载这个分库的连接。我现在项目做的由于不用整合mybatis 直接使用jdbcTemplate ，所以实现起来不是很麻烦。 思路主要就两个类；GetDynamicJdbcTemplate类：手动的创建连接。123456789101112131415161718192021222324252627282930313233343536/** * @ClassName GetDynamicJdbcTemplate * @Description 获取动态的jdbcTemplate * @Author zhulinfeng * @Date 2019/9/20 14:35 * @Version 1.0 */public class GetDynamicJdbcTemplate &#123; private String driverClassName; private String url; private String dbUsername; private String dbPassword; private JdbcTemplate jdbcTemplate; public JdbcTemplate getJdbcTemplate() &#123; return jdbcTemplate; &#125; public GetDynamicJdbcTemplate(String driverClassName, String url, String dbUsername, String dbPassword)&#123; this.driverClassName=driverClassName; this.url=url; this.dbUsername=dbUsername; this.dbPassword=dbPassword; this.jdbcTemplate=new JdbcTemplate(getDataSource()); &#125; public DriverManagerDataSource getDataSource() &#123; DriverManagerDataSource dataSource = new DriverManagerDataSource(); dataSource.setDriverClassName(driverClassName); dataSource.setUrl(url); dataSource.setUsername(dbUsername); dataSource.setPassword(dbPassword); return dataSource; &#125;&#125; GetJdbcTemplateMap类在项目启动的时候，会读取主库中的配置，将所有分库的连接都创建好放到map中。我们是按照地市分表的，接口在调用的时候根据前端传过来的地市就可以知道使用哪个数据库连接了。1234567891011121314151617181920212223242526272829303132@Component@Slf4j public class GetJdbcTemplateMap implements ApplicationRunner &#123; @Autowired @Qualifier("baseTemplate") private JdbcTemplate jdbcTemplate; public static Map&lt;String,JdbcTemplate&gt; JdbcTemplateMap=new HashMap&lt;&gt;(); @Override public void run(ApplicationArguments args) throws Exception &#123; String sql="CALL proc_baseinfo_cfg_dbsetting_query()"; List&lt;Map&lt;String, Object&gt;&gt; list = jdbcTemplate.queryForList(sql); if(list!=null &amp;&amp; !list.isEmpty())&#123; insertMap(list); &#125; &#125; private void insertMap(List&lt;Map&lt;String, Object&gt;&gt; list)&#123; for(Map&lt;String, Object&gt; map :list)&#123; String url="jdbc:mysql://" map.get("serverip") ":" map.get("dbport") "/" map.get("dbname") "?allowMultiQueries=true&amp;useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull"; log.info(url); String dbUsername= map.get("user").toString(); String dbPassword= map.get("password").toString(); GetDynamicJdbcTemplate getDynamicJdbcTemplate=new GetDynamicJdbcTemplate(ConstantClass.DRIVERCLASSNAME,url,dbUsername,dbPassword); JdbcTemplate jdbcTemplate=getDynamicJdbcTemplate.getJdbcTemplate(); JdbcTemplateMap.put(map.get("cityid").toString(),jdbcTemplate); &#125; &#125;&#125; 在接口中调用也很方便。 但是上面讲的只适合我们自己特有的业务，并且也没有整合mybatis ,所以我就没有写在我自己的项目中，这里提供出来是给大家一个思路。 番外也算是写完了这篇，感觉写的不是很好，但是有不知道怎么修改，暂时就先这样吧，后续有思路了再进行修改。又问问我为什么不先整合Thymeleaf 弄出页面来。之所以没有弄，是因为我想后期做前后端分离都是以接口的形式调用。所以想先将后端的部分都搭建好，再来整合前端的。好了，就说这么多啦，今天项目的代码也同步到github 上啦。github地址：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、springBoot 整合 mybatis 项目实战]]></title>
    <url>%2F20190919%2F%E4%BA%8C%E3%80%81springBoot%20%E6%95%B4%E5%90%88%20mybatis%20%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98.html</url>
    <content type="text"><![CDATA[前言上一篇文章开始了我们的springboot序篇，我们配置了mysql数据库，但是我们sql语句直接写在controller中并且使用的是jdbcTemplate。项目中肯定不会这样使用，上篇文章也说了，会结合mybatis 或者JPA 使用。我们这篇文章就来结合 mybatis 来使用吧，至于为什么选mybatis 而不是JPA ，这个看个人洗好吧。然后这篇文章会附带一讲一下今天为项目新增的配置。主要是为了保持项目和文章的一致性。 先贴出我们今天项目的结构吧，和昨天贴出来的差不多，在那基础上添加了一些东西，整个框架的模型算是成型了。 引入mybatis依赖一般改动都是从pom.xml 开始的，我们在昨天基础上的pom.xml 文件中加上mybatis 依赖,版本自己选吧。12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; Entry层昨天我们创建了一个user表 并插入了一条数据，我们就先用这张表吧，所以我们在entry 包中创建一个UserEntry 的实体类.代码如下：1234567891011121314@Getter@Setterpublic class UserEntry &#123; private int id; private String userName; private String password; private String email; private String roleCode; private String roleName; private String gmtCreate; private String gmtUpdate; private String nickname; private String userCreate;&#125; 可以看到这里用的注解和@Getter 和@Setter。这里就是避免代码中写入过多的get和 set 方法，使得代码变得更加简洁。 Dao 层Dao是用来处理数据的，这里我们引入了mybatis ,可以使用注解，也可以创建xml 文件，将sql 语句写在xml 文件中。我们这里就采用注解的方式吧，毕竟我们springboot项目，不想再出现xml配置文件了(后期也说不定哈哈)。 在dao包下创建一个userMapper 接口。代码如下：1234567891011121314@Mapperpublic interface UserMapper &#123; @Select("select id,username as userName,password,email,role_code as roleCode,gmt_create as gmtCreate,gmt_update as gmtUpdate,nickname as nickName,user_create as userCreate from sys_user") List&lt;UserEntry&gt; findUserList(); @Insert(&#123;"insert into sys_user(username,password,email) values('$&#123;user.userName&#125;','$&#123;user.password&#125;','$&#123;user.email&#125;')"&#125;) int add(@Param("user") UserEntry user); @Delete("delete from sys_user where id = #&#123;id&#125;") int delete(int id);&#125; 我们这里就先写一个查询、删除和插入的方法吧。可以看到，在接口上引入@Mapper 注解，然后就可以直接使用@Select 和@Insert 等注解啦，直接把注解sql 语句写在这里面就可以了。 Service 层service层我们一般都以一个接口和一个实现接口的具体类。 service 接口代码如下：123456789public interface UserService &#123; List&lt;UserEntry&gt; findUserList(); int addUser(String userName,String password,String email); int deleteUser(int id);&#125; serviceImpl 具体实现类。在service 包的impl 包创建 UserServiceImpl 类。代码如下：123456789101112131415161718192021222324252627@Servicepublic class UserServiceImpl implements UserService &#123; @Autowired protected UserMapper userMapper; @Override public List&lt;UserEntry&gt; findUserList() &#123; return userMapper.findUserList(); &#125; @Override public int addUser(String userName, String password, String email) &#123; UserEntry user=new UserEntry(); user.setUserName(userName); user.setPassword(password); user.setEmail(email); return userMapper.add(user); &#125; @Override public int deleteUser(int id) &#123; return userMapper.delete(id); &#125;&#125; controller 层我们在controller 包下的userinfo 包下创建UserController 类。代码如下：12345678910111213141516171819202122232425262728293031@Slf4j@RestController@RequestMapping("/user")public class UserController &#123; @Autowired private UserService userService; @RequestMapping(value = "/list",method = RequestMethod.GET) public List&lt;UserEntry&gt; findUserList()&#123; return userService.findUserList(); &#125; @RequestMapping(value = "/add",method = RequestMethod.GET) public String addUser(@RequestParam(value = "userName")String uaserName,@RequestParam(value = "password")String password,@RequestParam(value = "email")String email)&#123; int falg=userService.addUser(uaserName,password,email); if(falg&gt;0)&#123; return "success"; &#125; return "error"; &#125; @RequestMapping(value = "/delete",method = RequestMethod.GET) public String deleteUser(@RequestParam(value = "id")int id)&#123; if(userService.deleteUser(id)&gt;0)&#123; return "success"; &#125; return "error"; &#125;&#125; 测试好了，万事具备，来测试吧。我们启动项目后，在浏览器输入12添加一个用户http://localhost:9090/zlflovemm/user/add?userName=qaz&amp;password=123456&amp;email=123@qq.com 12查询所有用户http://localhost:9090/zlflovemm/user/list 12删除一个用户http://localhost:9090/zlflovemm/user/delete?id=19 都没有问题啦，说明基本的增删改查整合 mybatis 都是可行的。 配置多环境文件好了，大头讲完了，我们现在来讲讲项目今天进行了哪些配置。首先我们来看下我们项目中多了好几个配置文件。分别对应的是开发环境，测试环境，生产环境。毕竟我们在实际开发过程中，这三个环境都是经常有用到的，总会有数据库连接改来改去的问题。这里直接配置多份，想用哪个用那个就可以了。避免反复改容易出错的问题。我这里就暂时把连接mysql 的链接放到不同环境了。先在application.properties中加入12spring.profiles.active=dev表示用的是开发环境，就会读取application-dev.yml 文件中的配置。 application-dev.xml文件内容如下，另外两个文件也差不多，就不贴出来了。 配置日志项目中怎么能缺乏日志文件呢，我这里用的springboot 自带的日志框架logback 也很方便。我们先在application.properties 中加入1234#日志配置logging.level.org.springframework.web=infologging.config=classpath:logback.xmldebug=true 然后在 application.properties 同目录下创建一个 logback.xml.内容如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration debug="false"&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name="LOG_HOME" value="./logs" /&gt; &lt;property name="INFO_FILE" value="zlflovemm_log" /&gt; &lt;property name="ERROR_FILE" value="zlflovemm_error" /&gt; &lt;!--控制台日志， 控制台输出 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度,%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 文件保存日志的相关配置，同步 --&gt; &lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;Prudent&gt;true&lt;/Prudent&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt; $&#123;LOG_HOME&#125;/$&#123;INFO_FILE&#125;-%d&#123;yyyy-MM-dd&#125;.log &lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;[%t][%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- 文件保存日志的相关配置，同步 --&gt; &lt;appender name="ERROR" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;filter class="ch.qos.logback.classic.filter.ThresholdFilter"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt; &lt;Prudent&gt;true&lt;/Prudent&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt; $&#123;LOG_HOME&#125;/$&#123;ERROR_FILE&#125;-%d&#123;yyyy-MM-dd&#125;.log &lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125;[%t][%thread] %-5level %logger&#123;36&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;appender-ref ref="FILE"/&gt; &lt;appender-ref ref="ERROR" level="error" /&gt; &lt;/root&gt;&lt;/configuration&gt; 这样项目日志就配置好了，至于日志的具体配置，修改logback.xml 里面参数就可以了。和log4g差不多。 配置banner最后既然是一个项目，当然得有点标志性的东西，比如logo。springboot 给我们留下了一个彩蛋就是banner。我们可以在项目启动的时候，显示我们独一无二的logo .在application.properties 同目录下创建 banner.txt艺术字大家在网上自行搜索，这里就不推荐啦哈哈。这样我们在项目启动的时候就会加载我们的logo. 算是给广大的我们一点福利吧。 番外今晚总算是写完了，本来会早点的，但是不知道怎么就弄这么晚了。今天项目的代码也同步到github 上啦。github地址：https://github.com/QuellanAn/zlflovemm 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、springboot起航]]></title>
    <url>%2F20190918%2F%E4%B8%80%E3%80%81springboot%E8%B5%B7%E8%88%AA.html</url>
    <content type="text"><![CDATA[前言之前零零散散的学习了一些springboot的知识，以及搭建一些springboot的项目，甚至还有一些项目应用到实际项目中了，但是突然有一天想要建一个自己的项目网站。发现自己不知道从何开始。发现自己虽然用了很久，但是让自己 从头开始搭建一个却处处碰壁。所以静下心来好好的整理一下springboot的知识点。以及给自己搭建一个springboot 项目的脚手架。以后方便自己套用。 创建spring boot项目springboot的之所以火热便是因为开箱即用的特效，低配置甚至无配置使用，方便我们快速上手，我们这里先就什么都不配置吧。在idea 上直接可以创建springboot 类型项目。项目名就随便起吧，整个系列就都以这个项目为例啦，整个项目会分享到github 上，大家需要的可以跟着下载学习。建好的项目目录如下：其中选中的文件夹是我自己加的，因为我想整个项目的目录大概就是这个样子了。文件名起了zlflovemm 没有什么项目含义，起名太难了，就起了一个自己纪念的名字，大家勿怪。我们pom.xml 内容，因为后期不管是加其他组件，还是引用 jar 包什么的都是改这里。所以把最初版本拿出来。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.quellan&lt;/groupId&gt; &lt;artifactId&gt;zlflovemm&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;name&gt;zlflovemm&lt;/name&gt; &lt;description&gt;zlflovemm project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 可以看到pom.xml 文件里面东西很少了，parent 中是 springboot 版本信息。properties 是 jdk 版本信息。dependencies中的依赖只有一个starter-web 和starter-test 前面是这个项目支持web 项目，后面一个是支持单元测试，这两个都是创建项目的时候自带的。build 中就是项目构建打包的方式啦。这里暂时先用这种方式。 hello world我们还是来写一个hello world 吧，虽然有点幼稚，但毕竟遵循一下古训。我们在controller 包下创建一个demo 包。在demo 包下创建一个 demo.java . 12345678@RestControllerpublic class Demo &#123; @RequestMapping("/") public String demo()&#123; return "hello world"; &#125;&#125; 在controller 层用到的注解最多的就是@RestController 和@RequestMapping 了。@RestController和@Controller 注解是使用在controller层的。和@RequestMapping注解是用于设置映射路径的。这里注解就不深入讲解了，后面会进行深入的讲解。我们代码写完之后，我们来启动项目看一下，这里我们就直接运行 ZlflovemmApplication中的 main 方法就好了。然后在浏览器输入 1localhost:8080 到此原型已经搭建好了，可以发现我们什么都没有配置，都是使用的默认的配置，直接写的测试代码，然后就可以直接使用。 但是这样对于一个项目来说远远不够的，我们来为项目增加一些配置。 配置mysql其实一开始就配置mysql 太唐突了，但是一些小配置，不想再起一节，所以就一起了。 准备工作首先当然是创建数据库和表啦，这里idea 也可以连接mysql 数据库，我们就一切都在idea上操作吧。配置我们数据库连接，我这里已经在我的虚拟机上搭建好了mysql,说到搭建MySQL 也遇到一些坑。没有整理成单独的博客，大家可以参考Ubuntu18.04下安装MySQL连接好之后，我们执行一下sql ,创建数据库，创建表，插入数据。 12345678910111213141516171819CREATE DATABASE /*!32312 IF NOT EXISTS*/`zlflovemm` /*!40100 DEFAULT CHARACTER SET utf8 */;USE `zlflovemm`;CREATE TABLE `sys_user` ( `id` INT(11) NOT NULL AUTO_INCREMENT, `username` VARCHAR(255) NOT NULL, `password` VARCHAR(255) NOT NULL, `email` VARCHAR(255) NOT NULL, `role_code` VARCHAR(255) NOT NULL, `role_name` VARCHAR(255) NOT NULL, `gmt_create` DATETIME NOT NULL, `gmt_update` DATETIME NOT NULL, `nickname` VARCHAR(255) DEFAULT NULL, `user_create` INT(11) NOT NULL, PRIMARY KEY (`id`)) ENGINE=INNODB AUTO_INCREMENT=17 DEFAULT CHARSET=utf8;/*Data for the table `sys_user` */INSERT INTO `sys_user`(`id`,`username`,`password`,`email`,`role_code`,`role_name`,`gmt_create`,`gmt_update`,`nickname`,`user_create`) VALUES (1,'admin','123456','345849402@qq.com','admin','管理员','2019-03-21 14:30:57','2019-03-21 14:30:57','admin',1); 我们测试一下我们数据库建成功没有。 1select * from sys_user 这样说明我们数据库是没有问题的。 pom.xml 中添加依赖我们现在pom.xml 中添加依赖123456789101112131415&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; 前面两个是mysql 依赖，lombok 是方便我们getter方法和setter方法以及引入日志的。后面代码中会体现。 配置application.properties在application.properties中配置如下 12345678910111213141516server.port=9090server.servlet.context-path=/zlflovemmserver.tomcat.uri-encoding=UTF-8spring.http.encoding.charset=UTF-8spring.http.encoding.enabled=truespring.http.encoding.force=truespring.messages.encoding=UTF-8spring.datasource.driver-class-name=com.mysql.jdbc.Driverspring.datasource.url=jdbc:mysql://192.168.252.53:3306/zlfdb?characterEncoding=utf-8&amp;useSSL=false&amp;zeroDateTimeBehavior=CONVERT_TO_NULLspring.datasource.username=rootspring.datasource.password=123456spring.datasource.max-idle=10spring.datasource.max-wait=10000spring.datasource.min-idle=5spring.datasource.initial-size=5 前面配置访问端口为9090，访问路径为/zllovemm/，设置编码格式为utf-8.下面就是配置mysql 。 编写测试为了方便，我们就直接在controller编写测试。在controller包中建一个包 userinfo ,在userinfo中创建一个UserController并编写 12345678910111213@RestControllerpublic class UserController &#123; @Autowired private JdbcTemplate jdbcTemplate; @RequestMapping("/getUser") public List&lt;Map&lt;String, Object&gt;&gt; getUser()&#123; String sql="select * from sys_user"; return jdbcTemplate.queryForList(sql); &#125;&#125; 然后我们来启动项目，在浏览器中输入 1http://localhost:9090/zlflovemm/getUser 可以看到数据库是配置成功的。当然正式的项目肯定不能这样写，正式的项目会采用mybatis 或者JPA ,这个后期项目肯定也是会用的，所以这里就暂时这样写。 番外项目的雏形就先这样吧，后续加入其它组件，会继续在这个项目上跟新。github地址：https://github.com/QuellanAn/zlflovemm 这篇就到这里吧，也算是开篇了 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>springBoot</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、让我们开启单元测试之旅]]></title>
    <url>%2F20190910%2F%E4%B8%80%E3%80%81%E8%AE%A9%E6%88%91%E4%BB%AC%E5%BC%80%E5%90%AF%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E4%B9%8B%E6%97%85.html</url>
    <content type="text"><![CDATA[前言思量良久在考虑要不要写这一篇，是不是直接看门见山将在项目中怎么进行单元测试。最后想想觉得是不是太猴急了写那样，就好比你想和一个姑娘滚床单，是不是先应该请姑娘吃顿饭、送点礼物什么的。所以我才决定写这篇序言，让我们一起慢慢的揭开单元测试的面纱。 什么是单元测试这个在网上有很详细的解释。我这就简单的给出一个概念：单元测试是开发者编写一小段代码，用于检测被测代码的一个很小的、很明确的功能是否正确。 单元测试是对软件基本单元进行的测试，实际应用中是对public 函数进行的测试。执行单元测试，是为了验证某段代码的行为确实和开发者所期望的一致。 为什么要进行单元测试理由千千万，我只宠这三点： 减少调试时间 自动化测试 令设计变得更好 我们或多或少也都听说过单元测试，只知道用来检测写的代码有没有问题，这导致之前都没有写过测试用例，测试一些重要的方法最多也一个 main方法正常的数据调通了就过了，这样导致后期出现各种各样的问题，一遍遍的改代码，一遍遍的改bug。费时费力还不一定能处理好。我以为这是软件开发的诟病，其实不然，是因为我们不能确认我们写的那部分代码没有问题，所以总花费很长时间找问题上。所以才需要进行单元测试，虽然在刚开始写单元测试会花费时间，但是我们单元测试全都通过之后，我们对自己写的代码更有自信，可以确定没有代码没有问题了，而不是自己认为没有问题的那种。这样后期修复bug,也可以通过单元测试哪些执行成功哪些执行失败可以快速的定位到问题。我觉得这一点就足以让我们为我们写的代码编写相应的单元测试啦，毕竟找问题真是太痛苦，大家应该也深有体会。 单元测试怎么做简单而言，就是对一个 public 方法编写测试用例，那测试用例又怎么写呢？测试用例说白了也是一个方法，用来验证目标方法是否符合我们的预期。那这样就知道怎么写了吧，就是和我们平时写方法一样，但是它有一个标准俗称 “3A 模式” Arrange-Act-Assert（准备上下文环境–执行被测函数–断言）。也就是说一个测试用例的方法包含三部分就可以了。 测试用例应该具备的特征上面说的测试用例包含这三部分就可以了，那我们的测试用例应该具备怎样的特征呢，短小精悍且快准繁 小：一个测试几行代码（15）精准：一个测试之测一个场景隔离：每个测试都可以独立、重复运行，无耦合快：每个测试都应该是毫秒级别的频繁：应该频繁的执行，没增加、修改、删除一个测试都要运行一遍 那什么样的是好的单元测试呢？自动化可重复的彻底的独立的专业的 好的测试用例测试用例应该短小精悍且快准狠。这些是对测试用例的函数本身而言的，但在实际项目中出问题往往就是某些情况没有考虑到导致程序出错的，我们在自测的时候往往会测试正常数据的情况然而却忽略的了错误情况和边界值的测试，这些才是校验一个项目的健壮性的标准。所以好的测试用例必定是有全面的测试数据。那怎样获取全面的测试数据呢？在这之前需要知道哪些是好的测试数据 最优可能抓住错误的 不是重复的，多余的 一组相似测试用例中最有效的 既不是太简单，也不是太复杂 那怎样获取好的测试数据呢？有等价类划分法、边界值法、路径分析法。 等价类划分法等价类划分法是把所有可能的输入数据，划分成若干个子集，然后从每个子集中选取少数的具有代表性的数据作为测试用例。该方法是一种重要的、常用的黑盒测试用例设计方法。 有效等价类：对程序的规范说明是合理的，有意义的输入数据构成的集合。无效等价类：对程序的规范说明不是合理的或者无意义的输入数据构成的集合。 我们来看一个例子：计算两个点距离的函数 1public double getDistance(double x1, double y1, double x2, double y2) 边界值法边界值分析法是对输入或者输出的边界值进行测试的一组黑盒测试方法。 通常情况下，边界值分析法是作为等价类划分法的补充，这种情况下，其测试用例来自等价类的边界。 比如上面一个例子中取边界值做为测试用例。 路径分析法基本路径测试是一种白盒测试方法，它在程序控制图的基础上，通过分析程序的流程，构造导出基本可执行路径集合，从而设计测试用例的方法。 设计出的测试用例要保证在测试程序中的每一个可执行语句至少执行一次。我们来看一个例子可能的路径为： 12341-2-3-4-51-2-3-4-61-2-4-51-2-4-6 断言我们这里说的断言只是Junit断言，java 本身也有断言的，但是貌似我们使用的很少以至于我们都忘记了它的存在。Junit 断言说是断言，其实也就是一份方法，没有什么语法。我们测试用例中使用断言，也就是使用这些方法来进行验证是否达到我们的预期。方法有很多，大家可以看看源码，我这里给出几个常见的。|函数名|描述 ||–|–|| assertEquals| 判断实际产生的值与期望值是否相等||assertNull|判断对象是否为null||assertNotNull|判断对象是否为非null||assertSame|判断实际产生的对象与期望对象是否为同一个对象||assertNotSame|判断实际产生的对象与期望对象是否为不同的对象||assertTrue|判断bool变量是否为真||assertFalse|判断bool变量是否为假||Fail|使测试立即失败| 上面这样说好像没有什么效果，我们先来看其中一个断言方法的源代码。我们就看第一个assertEquals 吧可以看到有很多assertEquals方法。这样的方法的重载在底层很常见。我们来看下三个参数类似是Object的这个吧。 123456789101112131415161718192021222324252627282930313233343536public static void assertEquals(String message, Object expected, Object actual) &#123; if (!equalsRegardingNull(expected, actual)) &#123; if (expected instanceof String &amp;&amp; actual instanceof String) &#123; String cleanMessage = message == null ? "" : message; throw new ComparisonFailure(cleanMessage, (String)expected, (String)actual); &#125; else &#123; failNotEquals(message, expected, actual); &#125; &#125; &#125;private static boolean equalsRegardingNull(Object expected, Object actual) &#123; if (expected == null) &#123; return actual == null; &#125; else &#123; return isEquals(expected, actual); &#125; &#125; private static boolean isEquals(Object expected, Object actual) &#123; return expected.equals(actual); &#125;private static void failNotEquals(String message, Object expected, Object actual) &#123; fail(format(message, expected, actual)); &#125; static String format(String message, Object expected, Object actual) &#123; String formatted = ""; if (message != null &amp;&amp; !message.equals("")) &#123; formatted = message + " "; &#125; String expectedString = String.valueOf(expected); String actualString = String.valueOf(actual); return expectedString.equals(actualString) ? formatted + "expected: " + formatClassAndValue(expected, expectedString) + " but was: " + formatClassAndValue(actual, actualString) : formatted + "expected:&lt;" + expectedString + "&gt; but was:&lt;" + actualString + "&gt;"; &#125; equalsRegardingNull() 函数就是判断两个值是否相等，底层还是相当于用的object.equals()。如果两个值相等就断言通过，如果不相等就判断expected和actual是否是string类型，如果是直接将message输出。如果不是就failNotEquals().failNotEquals方法的源码我也贴出来了，可以看也很简单，就是message、expected、actual转换成string格式输出出来，并执行fail()使得测试失败。 从上面看断言也就不过如此(Junit 断言)。我们会使用常用的方法就可以写好测试用例啦，至于其他的方法，我们用到的时候可以直接其源代码，毕竟也不会很复杂。 简单案例目标代码及功能说明这段代码在项目中的作用是对特殊字段的对应的值进行处理并返回。如果字段是包含time，那将值改成日期格式返回。如果字段是包含iphone,那将值截取后11位返回。其他情况，直接返回。 12345678910111213141516171819202122232425262728293031323334public class DataHandle &#123; public static final String REGEX_MOBILE = "^((13[0-9])|(15[0-9])|(17[0-9])|(18[0-9])|(19[0-9])|(14[0-9]))\\d&#123;8&#125;$"; public String fieldDataHandle(String key,String value)&#123; //如果是时间类型，将时间戳转成时间 if(key.toLowerCase().contains("ipone"))&#123; //如果手机号长于11位，截取后11位 if(value.length()&gt;11)&#123; value=value.substring(value.length()-11); &#125; if(!isMobile(value))&#123; return null; &#125; &#125;else if(key.toLowerCase().contains("time"))&#123; value=timeStampToDate(value,"yyyy-MM-dd HH:mm:ss"); &#125; return value; &#125; private static String timeStampToDate(String time,String timeFormat) &#123; Long timeLong = Long.parseLong(time); SimpleDateFormat sdf = new SimpleDateFormat(timeFormat);//要转换的时间格式 Date date; try &#123; date = sdf.parse(sdf.format(timeLong)); return sdf.format(date); &#125; catch (Exception e) &#123; return null; &#125; &#125; private static boolean isMobile(String mobile) &#123; return Pattern.matches(REGEX_MOBILE, mobile); &#125;&#125; 单元测试设计等价类设计 等价类划分 有效等价类 无效等价类 key 包含time, 包含ipone,包含time和ipone 不包含time 和ipone value 时间戳，手机号，带区号的手机号 不是时间戳，也不是手机号 我们根据这个来设计测试用例|key|value |预期值||–|–|–||字段包含time | 时间戳 | 返回日期格式的的字符串 || 字段包含time | 不是时间戳 | null || 字段包含ipone |不是手机号 | null || 字段包含ipone |是11位的手机号 | 返回11位手机号字符串 ||字段包含ipone | 是手机号，但位数大于11位 | 返回11位手机号字符串|| 字段包含time,ipone |时间戳 | 返回日期格式的的字符串||字段包含time,ipone |不是手机号，也不是时间戳 | null ||字段包含time,ipone| 手机号| null||字段不包含time 和ipone |时间戳| 时间戳字符串||字段不包含time 和ipone |11位手机号| 手机号字符串||字段不包含time 和ipone |大于11位手机号 |返回值字符串||字段不包含time 和ipone| 不是手机号，也不是时间戳 |值对应字符串 | 编写测试用例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879public class DataHandleTest &#123; DataHandle dataHandle = null; @Before public void setup() &#123; dataHandle = new DataHandle(); &#125; @After public void tearDown() &#123; dataHandle = null; &#125; @Test public void testFieldDataHandle_包含time是时间戳_返回日期字符串()&#123; assertEquals("2019-09-10 19:02:30", dataHandle.fieldDataHandle("atime","1568113350000")); &#125; @Test public void testFieldDataHandle_包含time不是时间戳_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("atime","1568113350aaa")); &#125; @Test public void testFieldDataHandle_包含ipone不是手机号_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("bipone","aaa")); &#125; @Test public void testFieldDataHandle_包含ipone是11位手机号_返回手机号字符串()&#123; assertEquals("13265459362",dataHandle.fieldDataHandle("bipone","13265459362")); &#125; @Test public void testFieldDataHandle_包含ipone是大于11位手机号_返回手机号字符串()&#123; assertEquals("13265459362",dataHandle.fieldDataHandle("bipone","+8613265459362")); &#125; @Test public void testFieldDataHandle_包含time和ipone是时间戳_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("atimebipone","1568168656000")); &#125; @Test public void testFieldDataHandle_包含time和ipone是手机号_返回手机号字符串()&#123; assertEquals("13265459362",dataHandle.fieldDataHandle("atimebipone","13265459362")); &#125; @Test public void testFieldDataHandle_包含time和ipone不是时间戳手机号_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("atimebipone","aaabbb")); &#125; @Test public void testFieldDataHandle_不包含time和ipone是时间戳_返回时间戳字符串()&#123; assertEquals("1568114439",dataHandle.fieldDataHandle("ccc","1568114439")); &#125; @Test public void testFieldDataHandle_不包含time和ipone是11位手机号_返回时间手机号字符串()&#123; assertEquals("13112341234",dataHandle.fieldDataHandle("ccc","13112341234")); &#125; @Test public void testFieldDataHandle_不包含time和ipone是大于11位手机号_返回值字符串()&#123; assertEquals("+8613412341234",dataHandle.fieldDataHandle("ccc","+8613412341234")); &#125; @Test public void testFieldDataHandle_不包含time和ipone不是时间戳手机号_返回值字符串()&#123; assertEquals("abcdefg",dataHandle.fieldDataHandle("ccc","abcdefg")); &#125;&#125; 然后我们执行一下测试用例；可以看到有一个地方的测试用例是不通过的，那就说明有问题，我们看一下。 1234@Test public void testFieldDataHandle_包含time不是时间戳_返回NULL()&#123; assertNull(dataHandle.fieldDataHandle("atime","1568113350aaa")); &#125; 这个是抛异常了，因为日期格式转换错误，但是我们在日期转换的时候已经捕获了呀，并且返回为null 。那为什么测试用例没有通过呢，而是直接抛异常出来了，调试发现这个方法没有捕获到异常，而是直接抛出给Junit了。所以这里提示代码不能这么写。一般异常了不建议返回null.而是打印出异常把信息抛出。这里我们就不改了。我们将测试用例改一下，在测试用例中捕获一下异常。改成如下： 1234@Test(expected = NumberFormatException.class) public void testFieldDataHandle_包含time不是时间戳_throwsException()&#123; dataHandle.fieldDataHandle("atime","1568113350aaa"); &#125; 再全部执行一下这样就不抱错了。好啦这个就是一个简单的测试用例啦。 总结最后总结一下吧，我觉得应该知道以下几点 认识到单元测试的必要性 好的测试用例是关键 测试用例中断言必不可少 编写测试用例的规范要遵循 看到这啦的小伙伴，如果觉得喜欢就点个赞吧嘿嘿。如果有什么意见，欢迎给我提。嘿嘿。后续想写一下测试用例的规范，喜欢的可以持续关注❤ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>单元测试</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Junit</tag>
        <tag>单元测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内网穿透ngrok_ngrokcc_cpolar]]></title>
    <url>%2F20190905%2F%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8Fngrok_ngrokcc_cpolar.html</url>
    <content type="text"><![CDATA[前言先来说说问题吧，我们的项目在测试环境上搭建好了，也就是在内网上可以正常运行，但是呢，局方的人想要看一下效果先，那问题就来了，不在同一个局域网，他们访问不了我们的内网啊，现在又想看。这咋整。所以就有了这篇文章。这三个软件都差不多，都有一个免费的，我自己都试了一下，window和Linux的都可以，做演示的话问题不大。刚刚好满足要求。 官网ngrok:https://ngrok.com/ngrokc:http://www.ngrok.cc/cpolar:https://www.cpolar.com/ 大家对着官网教程来就可以了，无非都是注册会员，领取那个免费的authtoken.然后下载客户端，设置端口，启动项目，用域名进行访问。 说明1、ngrok 和 cpolar 基本用法都是一致的，都是生成一个authtoken ,然后设置一个ip和端口，会随机的生成一个http的域名和一个https 的域名随机访问。2、ngrokcc 是国内的一个网站，没有authtoken ,但是有隧道，需要你在控制台建好隧道，然后在客户端连接隧道id 就好了 1./sunny clientid 隧道id 总结使用起来还是比较简单，能满足我们将项目搭建在本地，用公网访问演示。 番外这几个是三个软件都是利用Nginx反向代理实现的。但是免费的只有一个隧道或者一个端口，这个时候我们可以在自己本地再搭建一个Nginx做虚拟主机，这样就可以自由飞翔了吧哈哈 再番外因为看了一下官方文档，发现不仅可以代理一个端口网站，还能代理tcp协议。 我来举一个例子。我有两台电脑，一台装的是win ,一台装的是Ubuntu，一般我都是把Ubuntu当做服务器用。两台电脑在同一个局域网直接用xhell 的ssh 连接起来当然很方便啦。但是我有时候需要把win 带到其他地方，那做服务器的那台电脑就不能访问啦，所以我参考一下官网的，可以在用外网访问这台服务器啦。操作也很简单，我三个也都测试了一下，用的是cpolar 的，感觉比ngrok 要稳定些。1、在我们Ubuntu服务器上安装好cpolar客户端，然后认证tocken 这些和之前是一样哒。2、 1cpolar tcp 22 就这么简单。 然后在主机和端口号填上对应的就好了，就是这么简单。 这样之后，就算两台电脑不在同一个局域网，也可以直接访问了，很实用。 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>建站之路</category>
      </categories>
      <tags>
        <tag>内网穿透</tag>
        <tag>ngrok</tag>
        <tag>ngrokcc</tag>
        <tag>cpolar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八、redis集群]]></title>
    <url>%2F20190903%2F%E5%85%AB%E3%80%81redis%E9%9B%86%E7%BE%A4.html</url>
    <content type="text"><![CDATA[前言前面写完了 Redis 的主从复制、哨兵模式、Redis 持久化方式。这篇文章开始写 Redis 集群啦。 我们项目中使用 Redis 一般都不是使用单台 Redis 提供服务，除非是很小的项目，不过很小的项目也没有必要使用Redis了。所以一般使用 Redis 都会配上 Redis主从备（就是前面将的主从复制），配上哨兵模式实现故障转移。更大的项目就搭建一个 Redis 集群。 但是呢，我们大多数在项目中即使使用了 Redis ，都是直接使用的，框架什么的都已经被前面的人搭建好了。所以我们在使用的时候其实就是配置的时候有些不同，代码中使用起来和单机的 Redis 是没有什么区别的。所以并不能说我们对 Redis 集群有多了解。 所以接下来，就让我们来了解一下 Redis 集群吧，手把手搭建一个 Redis 集群 ，让我们对 Redis 集群有更多的了解 。 什么是 Redis 集群进入正文啦，既然学习 Redis 集群，那什么是 Redis 集群呢？ Redis 集群是 Redis 提供的分布式数据库方案，集群通过分片( sharding )来实现数据共享，并提供复制和故障转移。 可以说上面这句话是对 redis 集群的高度概括了，redis 集群提供分布式数据库方案，前面我们将的主从复制和哨兵模式可以知道，只会有一个主服务器( master )。主从复制，只会有一个 master ，可以有多个 slave。而哨兵模式是在主从复制的基础上，发现 master 挂掉，会自动的将其中一个 salve 升级成 master 。但是最终结果还是只有一个 master。所以如果系统很大，对Redis 写操作的压力就会很大，所以才出现的集群的模式。集群模式可以有多个 master 。来看下面集群模式的图(下面的图不是最终版，便于理解的。后文有最终版的)：手动画的可能有点丑，但是大概的意思就是这样啦。单个节点就是我们之前了解的主从复制的一主多从(图中是一主两从)，加上哨兵模式，来监听节点的 master 是否正常。 那集群就是多个节点组成的，多个节点的 master 数据共享，横向分担单个节点 master 的压力。那从上图可以看出 哨兵模式 其实是 集群模式的一个子集，集群模式是哨兵模式的一个拓展。 Redis 集群有什么好处，用在哪些场景上面讲了什么是 Reids 集群，那为什么要使用 Redis 集群呢，不直接使用哨兵模式呢？使用 Redis 集群有什么好处呢？ 要回答上面这个问题，其实在上一节已经差不多介绍了，集群模式是哨兵模式的一种拓展，既然是拓展，当时是因为哨兵模式不能满足需求才会产生的。 在没有Redis 集群的时候，人们使用哨兵模式，所有的数据都存在 master 上面，master 的压力越来越大，垂直扩容再多的 salve 已经不能分担 master 的压力的，因为所有的写操作集中都集中在 master 上。所以人们就想到了水平扩容，就是搭建多个 master 节点。客户端进行分片，手动的控制访问其中某个节点。但是这几个节点之间的数据是不共享的。 并且如果增加一个节点，需要手动的将数据进行迁移，维护起来很麻烦。所以才产生了 Redis 集群。 所以 Redis 集群有什么好处，就是进一步提升 Redis 性能，分布式部署实现高可用性，更加的稳定。当然还包含主从复制的数据热备份以及哨兵模式的故障转移等有点啦。 那 Redis 集群用在哪些场景呢？ 其实我感觉一般较大的项目使用了 redis 的话，都会使用 redis 集群。毕竟在部署的时候先做好充分的拓展准备，比到时候项目出现瓶颈再去拓展成本就要小太多了。并且 Redis 是轻量级的，采用 redis 集群，也许在项目初期根本就用不上多个节点，单个节点就够用，多节点造成浪费。但是其实我们启动多个节点没有用到的话，节点所占用的内存和CPU 是非常小的。所以建议一般项目使用 Redis的话，尽量使用 Redis 集群吧。 集群的主从复制和故障转移Redis 集群的主从复制，其实和单机的主从复制是一样的。前面 Redis 集群结构图可以看到。单个节点中有一个 master 和多个 slave 。这些 slave 会自动的同步 master中的数据。注意的是，这些 salve 只会同步 所属的 master 中的数据，集群中其他的 master 数据是不会同步的。 同样的 ，当个节点中可以配置多个哨兵，来监控这个节点中的master 是否下线了，如果下线了就会将这个节点的slave 选择一个升级成 master 并继承之前 master 的分片，继续工作。 但是其实啊，在集群模式中，并没有配置哨兵，我们也能实现故障的自动转移。其实真正的集群的图是这样的：如图可以看到并没有为每个节点配置 sentinel 。那怎么实现对 master 的监听，实现故障的自动转移呢？ 我们在讲哨兵模式的时候说过，其实哨兵也是一种特殊的 redis 服务对吧。我们master 是通过 redis-server 启动的。我们哨兵是通过 redis-sentinel启动的。然后哨兵的作用就是定期的给 master 发送 ping检测 master 是否下线，然后通过选举的方式选择 slave 升级成 master那放在集群中可以发现，哨兵的这些工作，完全可以交给master 来做。之前单个节点，master 做不了才交给 sentinel 的。现在有多个 master ，当然就可以用 master 来代替salve 的工作啦在集群中，每个节点的master 定期的向其他节点 master 发送 ping命令，如果没有收到pong 响应，则会认为主观下线，并将这个消息发送给其他的 master。其他的 master 在接收到这个消息后就保存起来。当某个节点的 master 收到 半数以上的消息认为这个节点主观下线后，就会判定这个节点客观下线。并将这个节点客观下线的消息通知给其他的master。这个客观节点下线后，其他的 master 节点 就会选举 下线的master中的 slave 一个变成 新的master 继续工作。从而实现故障自动转移。这个选举过程和哨兵模式中是一样的，只不过是 master 代替了 sentinel 的工作。 搭建一个 Redis 集群的实例好接下来让我们一起来搭建一个集群模式吧，因为我只有一台服务器，所以我集群就搭建在一台服务器上，在实际项目中肯定是多台服务器搭建集群的。但是搭建的方式都是一样的。这里我将两种集群的搭建方式，第一种是手动的搭建集群，手动分片，这种方便我们对集群有更多的了解，第二种的话借助 Redis 自带的辅助工具来搭建集群，方便快捷。 方式一好了，让我们开始吧，在开始之前，我们不用觉得搭建集群很麻烦，其实一样的是修改redis.conf配置文件中的内容。只需要将配置文件中集群模式打开就可以了。如下：1cluster-enabled yes 是不是很简单，还是不说废话的，搞起来。 准备工作先创建一个 cluster 目录，然后在 cluster 目录下创建6个文件夹。因为的演示中我的cluster 目录已经占用了，我就再创建是cluster2 目录。 123456789cd /usr/local/redis/etcmkdir cluster2cd cluster2mkdir 8000mkdir 8001mkdir 8002mkdir 8003mkdir 8004mkdir 8005 然后将redis.conf文件copy到这六个文件中。 123456cp ~/workSpace/redis-4.0.9/redis.conf ./8000/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8001/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8002/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8003/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8004/redis.confcp ~/workSpace/redis-4.0.9/redis.conf ./8005/redis.conf 修改配置文件准备工作做好了，现在我们来修改这六个目录下的配置文件吧。都将开启集群模式。 1vim ./8000/redis.conf 修改配置文件如下，我们为了方便就先不进行太复杂的配置，我们就配置搭建集群最小力度修改。 12345port 8000daemonize yescluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000 上面修改的是8000这个目录下的redis.conf ，接下来我们按部就班的把其他几个文件中的配置也进行修改。和上面的基本一样。这里就不一一写出来了。贴一个8002的修改，大家就一目了然了。 12345port 8002daemonize yescluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000 启动修改好这几个配置文件后，然后就启动这些服务 1234567891011121314151617cd /usr/local/redis/etc/cluster2/8000/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8001/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8002/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8003/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8004/redis-server ./redis.conf cd /usr/local/redis/etc/cluster2/8005/redis-server ./redis.conf 如下图：上图可以看到，会先进入到对应的文件夹，然后启动redis服务，为什么要先进入对应的文件夹呢？因为我们配置了cluster-config-file nodes.conf 这个会在你启动目录下生成一个node.conf 文件，用来存放当前节点信息。所以你不先进入对应目录的话，很很可能就启动不成功哟。下图可以看到生成了 node.conf 以及里面的内容。我们在来通过线程的方式查看一下 1ps -ef |grep redis 可以发现我们启动的6个节点都已经启动了，并且后面都带有 cluster 的标识。和 6379 单机模式有区别。 节点互通到此准备工作算是真正的做完了，我们启动了六个节点，但是现在这六个节点是相互独立的，没有任何关联，那我们怎么将它们关联起来呢？我们先用客户端进入到8000节点。查看一下节点信息 12redis-cli -p 8000cluster nodes 可以看到只有自身这个节点的信息。现在我们和其他节点建立连接 1cluster meet ip port 下图可以看我们和8001节点建立连接，这个时候再查看nodes节点信息，发现就有两个节点信息啦，说明这个集群中现在存在了8000 和8001 两个节点。我们现在把8002 节点也加进来。这样原本的各自独立的节点就在同一个集群中啦，大概就是下面这张图（有点丑，将就看） 槽指派上面已经进行了节点互通了，多个节点在同一个集群中了，那我们是不是就可以使用集群了呢？其实不行，我们来看一下cluster info发现 cluster_status 还是fail。表明还是不可用的。因为我们还没有进行卡槽的分派。Redis 集群是通过分片的方式来保存数据库中的键值对的，集群整个数据库被分成16384个槽（slot）。也就是说所有数据的key都会映射到对应的 slot 中。只有当数据库中16384 个槽都在节点上有分派，集群才会上线，否则集群的状态就是 fail。所以接下来开始槽指派吧 12345cluster addslots slots[slots]样例：cluster addslots 0 1 2 cluster addslots 0 1 2 ... 5000cluster addslots &#123;0..5000&#125; 网上说的可以支持范围分配的，但是我电脑上试了 N 种方法都不行，我的 redis 版本是4.0.9 的。最后没办法，写了一个脚本跑的。如果大家也不行的话，可以用脚本跑吧。 123456789start=$1end=$2port=$3for slot in `seq $&#123;start&#125; $&#123;end&#125;`do echo "slot:$&#123;slot&#125;" redis-cli -p $&#123;port&#125; cluster addslots $&#123;slot&#125; done~ 然后执行： 123sh add-slots.sh 0 5000 8000sh add-slots.sh 5001 10000 8001sh add-slots.sh 10000 16384 8002 这样就可以把16384个卡槽分配到三个节点上啦，如果有多个节点，自己调整分配哈，我这里是以三个节点为例的。 卡槽分配完成以后，我们在来看看 cluster 的状态发现 cluster_status 变成 ok 了。说明我们的卡槽分配是成功的。 验证那现在集群上线了，是不是就可以用了呢?答案是是的，但是配到现在为止还有点瑕疵，瑕疵我们待会再说，先来看看集群能不能操作命令。可以看到，进行槽指派之后是可以进行正常的操作的，这里的set a 123提示我移动到8002端口执行。因为a 对应的卡槽为15495.这里有一个命令和可以查看key值在哪一个卡槽，从而属于哪一个节点。 123127.0.0.1:8000&gt; CLUSTER KEYSLOT a(integer) 15495127.0.0.1:8000&gt; 那假如我就想set a 呢，难道要先切换到8002端口，那岂不是很麻烦，还有另一种方法： 1redis-cli -c -p 8000 可以看到这样启动客户端，会自动的将数据存入到对应的节点上，并切换到这个节点，并且之前我在8000 端口上set data 123,我现在在8002端口上get data 会自动的找到key值并切换到8000端口上，这样在客户端就感觉这三个节点是一个整体啦，是不是很方便。 配置主从前面为止，集群模式已经搭建好了，但是呢前文说的还有点瑕疵，现在就来说说，我们现在搭建的集群只有三个主节点，任何一个主节点挂掉了，就会导致集群不可用，因为集群可用的标志是 16384 个卡槽全部都分配到可用的节点上。所以我们现在搭建的集群还是不稳定的。所以为了解决这个问题，我们需要为每一个主节点配置一个从节点。从节点的作用是数据热备份和当主节点出现故障时可以替代主节点进行工作。 好了，我们来搭建主从吧，前文中我们创建了6个节点，还有三个没用，其实就是用来搭建主从的哈哈。还没有用到的这三个节点 和搭建好的这个集群是独立的现在。第一步，将这三个节点加入到集群中来。 123cluster meet 127.0.0.1 8003cluster meet 127.0.0.1 8004cluster meet 127.0.0.1 8005 第二步，查找主节点的 nodesId。通过 cluster nodes可以查到到集群中所有节点的信息，第一列就是每个节点的nodesId.第三步，将从节点和主节点关联起来。 123redis-cli -p 8003 cluster replicate 9a86d899be55a37d3ac1c8be6c342c7f59513076redis-cli -p 8004 cluster replicate 03efbb8782a705d5978f5c1b14d4dcba14a167e8redis-cli -p 8005 cluster replicate 01f6c1888b7a103c10fffe9cf6be8a5fff8ae985 我们再来看看节点信息可以看到从节点已经搭建成功啦，那到底有没有成功呢，我们再来试试，我们手动模拟主节点8000故障了。我们用shutdown可以关闭当前节点的服务。看一下进程确定8000已经关闭了我们现在进入8001端口看一下，get data可以看到切换到8003端口上了，8003端口是8000端口的从节点，现在8000端口挂掉了，8003端口会代替8000端口继续工作。我们看一下cluster nodes 发现8000端口节点是 fail 的，8003端口升级成master了。我们现在修复了8000端口问题，将其重启起来看看。 1234quellanan@quellanan-Lenovo-G400:/usr/local/redis/etc/cluster2/8000$ redis-server ./redis.conf 26401:C 03 Sep 10:13:31.777 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo26401:C 03 Sep 10:13:31.777 # Redis version=4.0.9, bits=64, commit=00000000, modified=0, pid=26401, just started26401:C 03 Sep 10:13:31.777 # Configuration loaded 然后看看节点信息，发现8003端口变成了主节点，8000端口变成了8003端口的从节点。这和我们之前哨兵模式是一样的。好啦，到此为止，一个集群算是真正的搭建好啦。一步一步的来，不难，就几个命令而已，可能我写得比较啰嗦嘿嘿。 方式二准备工作第二种方法搭建集群就简单讲啦，准备工作和启动都是一样的，只是不用我们自己进行节点互通和分配卡槽啦。如下图，我已经启动 7000~7005 六个节点。 安装软件123yum install rubyyum install rubygemsgem install redis 我这里已经安装好了，就不演示啦。 配置执行以下命令，就会自动的帮我们进行节点互通，分配卡槽以及设置从节点。1./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 特别提醒，这里的IP用主机的IP，如果使用127.0.0.1的话，在我们代码中访问会出错，我也是在项目中使用的时候碰到的上面就已经搭建好集群啦，简单吧。 验证我们现在简单验证一下，进入7000节点； 1redis-cli -c -p 7000 可以看到集群是上线状态，可以正常使用啦，我们简单操作一波好啦，集群搭建的实例就说这么多吧，两种方式，第一种是原生的，第二种是借助工具的，效果是一样的。还有一个内容就是重新分片。这个用到的不多，我们前期在搭建集群的时候先预留多个节点就好，不然后面要扩容，就需要用到重新分片，感兴趣的可以在讨论区讨论下吧，也不难，这里就不写了(文章太长啦)。 在项目中使用集群在项目中使用集群，我这里就简单的给一个样例给大家参考。 创建一个springboot 项目基本上一直next 就好了。 修改pom.xml文件12345678910111213141516171819202122232425262728293031&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Redis使用starter--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--注解日志/get/set--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 修改application.yml123456789101112131415161718server: port: 9090# redis 集群配置spring: redis: cluster: nodes: 192.168.252.53:7000,192.168.252.53:7001,192.168.252.53:7002,192.168.252.53:7003,192.168.252.53:7004,192.168.252.53:7005 timeout: 6000ms # 连接池超时时间（毫秒） # 密码没有可以不填 password: database: 0 # 数据库索引 lettuce: pool: max-active: 8 # 连接池最大活跃连接数（使用负值表示没有限制） max-idle: 8 # 连接池最大空闲连接数 max-wait: -1ms # 连接池最大阻塞等待时间 毫秒（使用负值表示没有限制） min-idle: 0 #最小空闲连接数 配置dao层这个样例是我写的另一篇博客样例改编过来的，大家不知道项目结构的可以看一下我这篇博客中样例的项目结构。Redis在SpringBoot中使用案例创建dao 包，创建一个User 类,这里使用了lombok提供的@Getter 和@Setter 非常方便，代码看着也很简洁。 1234567891011121314151617181920@Getter@Setterpublic class User implements Serializable &#123; private static final long serialVersionUID = 1L; private Long id; private String userName; private String password; private String email; private String nickname; private String regTime; public User(String email, String nickname, String password, String userName, String regTime) &#123; super(); this.email = email; this.nickname = nickname; this.password = password; this.userName = userName; this.regTime = regTime; &#125;&#125; 创建service层创建一个service 包，创建一个RedisService类，代码如下： 12345678910111213141516171819202122232425262728@Service@Slf4jpublic class RedisService &#123; @Autowired private StringRedisTemplate stringRedisTemplate; public boolean setUserBystringRedisTemplate(User user)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(user.getNickname(),JSONObject.fromObject(user).toString()); return true; &#125; public String getUserBystringRedisTemplate(String name)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return JSONObject.fromObject(ops.get(name)).toString(); &#125; public boolean setString(String key,String value)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(key,value); return true; &#125; public String getString(String key)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return (String)ops.get(key); &#125;&#125; 创建Controller层创建一个controller 包，创建一个RedisController类代码如下： 12345678910111213141516171819202122232425262728293031@RestControllerpublic class RedisController &#123; @Autowired private RedisService redisService; @RequestMapping("/setUser") public String setUser()&#123; User user=new User("aa@qq.com","quellan","123456","朱",new Date().getTime()+""); redisService.setUserBystringRedisTemplate(user); return "添加成功"; &#125; @RequestMapping("/getUserByStringRedisTemplate") public String getUserByStringRedisTemplate()&#123; String name="quellan"; return redisService.getUserBystringRedisTemplate(name); &#125; @RequestMapping("/setString") public String setString(String key ,String value)&#123; redisService.setString(key,value); return "添加成功"; &#125; @RequestMapping("/getString") public String setString(String key)&#123; return redisService.getString(key); &#125;&#125; 测试到此为止，代码就已经写完啦，我们来启动项目测试一下。项目启动成功之后，我们调接口看看 1234567http://localhost:9090/setString?key=a&amp;value=123http://localhost:9090/setString?key=b&amp;value=1qazhttp://localhost:9090/setString?key=data&amp;value=wsxcdhttp://localhost:9090/getString?key=ahttp://localhost:9090/getString?key=datahttp://localhost:9090/setUserhttp://localhost:9090/getUser 我就截图看其中两个界面上没有问题啦，我们再用客户端看一下。 1redis-cli -c -p 7000 数据在集群中正常的读取是没有问题哒。 好了，在项目中简单使用集群就讲到这里啦，源代码我github上了，感兴趣的同学可以看下。demo源代码 总算写完了，可能写的不是很好，大家有疑问的，可以提出来，我知道的尽量给大家解答，谢谢大家！ 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[七、Redis持久化的两种方式RDB和AOF理解]]></title>
    <url>%2F20190822%2F%E4%B8%83%E3%80%81Redis%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E5%BC%8FRDB%E5%92%8CAOF%E7%90%86%E8%A7%A3.html</url>
    <content type="text"><![CDATA[前言前面将了redis的主从复制以及怎么搭建，还介绍了哨兵模式以及哨兵模式的搭建。虽然操作跟上了，但是还是补一下redis的持久化。redis之所以这么流行，很大一部分原因便是持久化，断电重启数据不消失，使得redis在数据库领域中站稳了脚。前文将的主从复制其实就是依赖持久化的，如果没有持久化，这些数据都不会从主服务器备份到从服务器。下文我们就讲讲redis的持久化。 说起redis持久化，大家或多或少都知道一些，简单点一句话也能概括。redis通过RDB和AOF方式将数据存入磁盘，实现持久化。RDB是定期生成快照存入磁盘中，AOF是将写操作存入磁盘中。二者各有优劣，RDB 是存放数据库中数据，适合做数据备份，但是数据可能不全，最近几分钟的数据可能没有。AOF是每秒中执行一次，如果有写操作的命令就存储起来，最多只会丢失1秒钟的数据，适合做数据恢复。但是这个就不适合做数据备份了，并且由于每秒都会执行多多少少会抢占redis的内存，会影响性能。但是在实际应用中是二者是配合使用的。 下面就来具体的讲讲RDB和AOF吧 RDBRDB 的全称是 redis database. 顾名思义，RDB就是将redis数据库，用来存储数据的，所以通过RDB方式持久化就是将存在redis内存中的数据写入到RDB文件中保存到磁盘上从而实现持久化的。RDB文件是一个压缩的二进制文件，通过这个文件可以还原redis数据库的数据，从而达到数据恢复的目的，借用一下《redis设计与实现》讲的这张图，途中数据库状态可以理解为redis内存中存储的数据。既然RDB持久化的方式是生成RDB文件，那么这个RDB文件是怎么生成的呢？RDB文件生成的方式有两种，一种是通过命令手动生成快照，还有一个是通过配置自动生成快照。下面我们来分别看看。 通过save和bgsava命令生成RDB文件这两个命令都是可以直接运行的。 save命令，会阻塞服务器进程，只有当RDB文件生成成功才会接着响应服务端的其他命令。而bgsave ，既然有这个命令，肯定是和save有所不同的，bgsave 不会阻塞服务器进程，会创建一个子进程来创建RDB文件但是注意的是使用bgsave命令的时候，虽然是通过子进程生成RDB文件，不会阻塞服务进程，其他的命令可以执行，但是有几个命令是不能执行的。 123save bgsavebgrewriteaof 在bgsave 期间 服务器拒绝这三个命令，主要是方式线程间竞争产生问题。 通过配置文件自动生成RDB初了手动执行这两个命令外，还可以在配置文件中配合参数，达到条件的时候就会自动的生成RDB打开我们的配置文件redis.conf,找到如下图，这个是默认的配置。 1234567save 900 1 表示在900秒内，如果发生了一次写操作，就触发bgsave命令生成RDB同理 save 300 10 在300秒内，发生了10次写操作，就触发bgsavesave 60 10000 在60秒内发生了10000次写操作，就触发bgsave 上面的这些可以进行配置，可以看到默认的设置，如果短时间内发生大量的写操作就会自动的触发bgsave ,生成RDB文件， 防止数据丢失。 好了，上面虽然说达到这三个条件中的一个，redis就会自动的生成RDB文件，那系统是怎样控制，又是怎样识别是否满足条件呢？原来啊，服务器维持了一个dirty 计数器，以及一个lastsave属性。dirty 计数器记录着从上次save/bgave 到现在发生了多少次写操作，没进行一次写操作，计数器就加1比如 12345set a 123计数器dirty 加1 set a 123 b 234 c 456计数器dirty 加3 而lastsave 是unix时间戳，记录上次save或bgsave的时间。有了这两个属性，就可以判断什么时候执行啦，redis服务器会周期性的执行serverCron函数,默认的话是每100毫秒执行一次。这个serverCron 函数先通过当前时间减去lastsave 获取时间间隔。如果dirty 大于 saveparm.chranges并且时间间隔大于saveparm.seconds那么就会触发bgsave 生成 RDB文件 其中saveparm.seconds 和saveparm.chranges 分别对应的是配置文件中设置的save 900 1等。 既然生成了RDB文件，我们只知道RDB是一个压缩的二进制文件，那RDB文件到底结构是什么样的呢？我看了一下《redis 设计与实现》没有怎么看明白哈哈，感兴趣的可以去看看。 RDB方式就讲到这里了，记住RDB方式，是定时的执行bgsave 命令生成RDB文件保存在磁盘上实现持久化的。适合数据备份，用于数据恢复可能会丢失最近几分钟的数据。 AOF全称是append only file. AOF 持久化的方式是通过redis服务器记录保存下所有的写命令到AOF文件存放在磁盘上，实现持久化的，看下图：怎样采用AOF的方式持久化呢？打开我们的配置文件，在配置文件中找到appendonly 改成yes 就可以采用AOF的方式备份了我们启动redis服务，为了测试方便，我们新启的一个redis服务，数据库中没有任何key我们看看appendonly.aof 也是没有任何东西的。现在我们存入一个key然后我们来看下aof文件的内容：可以看到，初了一些$3等一些特殊符号外我们可以看到我们执行的命令。 12select 0set a bbb 但是我们一些读操作的就不会记录。由此可见，AOF 持久化就是将所有的写操作存入AOF文件中，当数据恢复的时候，执行AOF文件中的命令就可以获取数据了。 我们接着来看那，我向数据库中先加一个key b ,然后删除key a .好了，现在我们再来看看aof 文件中是什么情况。可以看到命令有： 1234select 0set a bbbset b ddddel a 所以aof 文件中包含了这四条命令，到这大家有没有发现一个问题，如果我重复的对某一个key值进行操作，那么aof文件中就会记录所有的操作命令，但是实际上只有最后一次操作才是有效的，那这个aof文件中是不是就有很多冗余的数据呢？ 实际上是这样的，那怎么解决这个问题呢？这里就要提到一个命令啦 1BGREWRITEAOF 和RDB中的save 以及bgsave 是类似的。不过bgrewriteaof 命令的作用是重写aof文件，为什么要重写呢，就是为了解决aof文件中冗余的问题。我们先来手动执行一下这个命令然后看看aof 文件中的内容可以看到命令变成了 12select 0set b ddd 重写之后，aof的文件里的命令就是有效的啦，但是我们总不能自己手动执行bgrewriteaof 命令吧，那我们在哪里配置呢?在redis.conf 配置文件中有这两个参数。 auto-aof-rewrite-percentage 100 当Aof log增长超过指定比例时，重写log file， 设置为0表示不自动重写Aof 日志，重写是为了使aof体积保持最小，而确保保存最完整的数据。 auto-aof-rewrite-min-size 64mb 触发aof rewrite的最小文件尺寸 也就是说在实际应用中，如果开启了aof 备份，可以设置这两个参数来重写AOF文件。 好了上面说了那么多，那redis服务怎么通过aof文件来恢复数据的呢？其实很简单，就是将aof 文件中的命令一条一条的读取出来执行。看下图 最后再说一点嘿嘿。我们在配置文件中同时启用了RDB 和AOF ,那么服务启动的时候，会在用那个文件来回复数据呢？看下面这张图。可以看到如果启动aof ,就会采用aof 文件来回复数据，这是为什么呢，因为AOF 文件更新的频率更高，模式一秒中一次，所以用AOF 恢复的数据更加准确。 好了，只有这么多了哈哈，推荐大家看看《redis 设计与实现》也不建议大家从头往后看，调感兴趣的看吧，毕竟里面还是有很多原理对我们而言也不是一定非得弄懂的，大概了解一下就行，我比较懒哈哈。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[六、主从复制原来这么简单]]></title>
    <url>%2F20190821%2F%E5%85%AD%E3%80%81%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8E%9F%E6%9D%A5%E8%BF%99%E4%B9%88%E7%AE%80%E5%8D%95.html</url>
    <content type="text"><![CDATA[什么是redis主从复制总所周知redis之所以火因为它有着读取速度快，可持久化的优点。redis的持久化保证了断电或重启数据不会丢失。但仅仅这样是不够的的，持久化是将数据定期写入磁盘中，万一哪一天这一台服务器挂掉了，那所有数据依旧会丢失。为了解决这个单点故障问题，所以就有了主从复制。 主从复制就是 将一台redis服务器的数据自动的复制到其他redis服务器上。 一台服务器出故障的概率很高，但是多台服务器同时出故障的概率就很低了吧。所谓主从主从，当然是有主服务器 (master) 和从服务器 (slave) 啦，一个 master 可以将数据复制到多个 slave，但是特别注意的是，复制是单向的，只能从 master 到 slave 。一个master 可以有多个 slave ，一个slave 也可以有多个slave ,但是一个 slave 只能从属一个master 。如下图这样就是错误的。 主从复制的作用及场景1、数据冗余： 主从复制实现了数据的热备份，相当于一份数据在多个服务器上存储了，是持久化之外的一种数据冗余方式，这样做的目的是以空间换取安全性。如果主服务器挂掉了，可以通过从服务将数据恢复。 2、故障快速修复：当 master 出现问题的时候，可以快速的将一个 slave 切换成 master 继续提供服务 ，保证项目稳定性。 3、读写分离： 主从复制实现读写分离非常简单，写入的时候只操作 master ，读取的时候只操作 slave ，这样读的话可以多个slave 满足项目高并发的操作。 4、负载均衡：既然实现了读写分离，当然就能实现负载均衡，多个 slave 承担 数据读取操作 ，从而分担 master 服务器的压力。 5、高可用的基石：主从复制还是哨兵模式和集群模式能够实施的基础。 既然主从复制有这些作用，那在实际应用中会用在哪些场景呢？ 1、如果项目对数据安全性稳定性要求较高，就会使用主从复制搭建哨兵模式或者搭建集群。 2、海量数据读写，需要做读写分离提高防蚊效率，就会用到主从复制 3、容灾恢复，如果对数据依赖度很高，害怕数据在服务器挂掉后丢失，就可以通过主从复制防止数据丢失。 主从复制的模式一主一从这种模式在实际应用中还是比较少见的其实，一主一从主要是实现读写分离和容灾恢复。考虑到成本的问题，所以采用两台服务器，一个redis服务器master 负责读操作，并定期的复制到 另个一服务器slave 。slave 服务器负责读写操作。在项目中配置的时候配置两个redis连接。 一主多从一主多从有可以分为几种，如下图：这种就是所有的 slave 都从 master 中 进行复制，这样的好处是 配置简单，所有的slave 都只用关系 master 就好了，但是要考虑到其实复制也是会侵占CPU内存的，所有的slave 都从 master 复制，可能增大 master的负荷。 再来看看下图：这种模式也是一主多从，但是和上面的所有的 slave 都从 master 复制不一样。它是使一个到两个slave 从master 直接复制，其他的slave 从这两个slave 中复制。存在层级关系。这样的好处的降低的master 服务器的负荷，但是这样会导致如果中间某个 slave 挂掉了，那依附于它的所有slave 都不能用了。 主从复制部署这里我使用的是Ubuntu安装的redis，redis怎么安装，可以看我这篇文章Redis安装。安装好redis后，我们启动看看是否正常 12redis-server /usr/local/redis/etc/redis.confredis-cli -a 123456 证明是redis是正常启动的，那现在怎么配置主从模式呢？按理说主次模式的redis服务器当然是搭建在不同的服务器上，但是我们条件有限，我这里的三台redis服务都搭建在一个服务器上，只是他们监听的端口不同。 1、修改redis.conf我们先修改master的配置文件redis.conf 的一些配置 123456bind 0.0.0.0 表示可以被所有机器访问。daemonize yes 表示可以后台启动port 6379pidfile /var/run/redis_6379.pidlogfile "/usr/local/redis/logs/log_redis.log"requirepass 123456 2、复制两份redis.config改好redis.conf 后，将/usr/local/redis/etc/ 目录下的redis.config 复制两份为redis_slave1.confredis_slave2.config 3、修改rdis_slave1.conf12345678910bind 本机ip 表示只能本机访问daemonize yes port 6389pidfile /var/run/redis_6389.pidlogfile "/usr/local/redis/logs/log_redis_slaveof6389.log"requirepass 123456 ---上面的这些配置和redis.conf中基本一样修改一下就好了，日志是为了方便查看。下面看重点配置slaveof 192.168.252.53 6379 设置master的ip 和portmasterauth 123456 设置master的登录密码，就是redis.conf 中配置的requirepass 4、修改redis_slave2.conf同样的12345678bind 192.168.252.53daemonize yes port 6399pidfile /var/run/redis_6399.pidlogfile "/usr/local/redis/logs/log_redis_slaveof6399.log"requirepass 123456 slaveof 192.168.252.53 6379 masterauth 123456 5、启动redis服务123redis-server /usr/local/redis/etc/redis.confredis-server /usr/local/redis/etc/redis_slaveof1.confredis-server /usr/local/redis/etc/redis_slaveof2.conf 查看一下进程 1ps -ef | grep redis 6、启动客户端都启动来了，现在连到单个redis服务器看看 12345主服务redis-cli -a 123456从服务redis-cli -h 192.168.252.53 -p 6389 -a 123456redis-cli -h 192.168.252.53 -p 6399 -a 123456 7、测试启动3台客户端，分别连上master和两个slave在master中 1set c 122 在slave1和slave2 中分别 1get c 这样就说明你的主从复制服务已经搭建好啦。 8、问题记录上面的是一个完美的过程搭建的主从复制的例子，但是我相信在实际搭建的时候肯定会出现各种问题，现在记录下我搭建的时候出现的问题吧1、权限问题在搭建好主从服务后，进入从节点查看info replication发现1master_link_status:down 表明主从节点并没有建立连接，但是但是为什么一直是down 呢，看了一下日志提示不能打开rdb这个快照，当然就不能将内容复制到从节点啦，再一看这个路径，是我自己建的路径，第一反应就是权限问题，然后进这个目录一看，发现我的etc目录是root用户的。所以就修改了文件的用户和用户组。在进到etc目录下，就发现了两个快照，再去看的时候发现down变成up 了。 1234567891011121314151617181920quellanan@quellanan-Lenovo-G400:/usr/local/redis$ sudo chown quellanan etc[sudo] quellanan 的密码： quellanan@quellanan-Lenovo-G400:/usr/local/redis$ sudo chgrp quellanan etcquellanan@quellanan-Lenovo-G400:/usr/local/redis$ ll总用量 20drwxr-xr-x 5 root root 4096 8月 8 16:50 ./drwxr-xr-x 13 root root 4096 8月 1 16:28 ../drwxr-xr-x 2 root root 4096 8月 1 16:57 bin/drwxr-xr-x 2 quellanan quellanan 4096 8月 15 09:50 etc/drwxrwxrwx 2 root root 4096 8月 15 09:16 logs/quellanan@quellanan-Lenovo-G400:/usr/local/redis$ cd etc/quellanan@quellanan-Lenovo-G400:/usr/local/redis/etc$ ll总用量 196drwxr-xr-x 2 quellanan quellanan 4096 8月 15 09:50 ./drwxr-xr-x 5 root root 4096 8月 8 16:50 ../-rw-r--r-- 1 quellanan quellanan 188 8月 15 09:50 dump6389.rdb-rw-rw-r-- 1 quellanan quellanan 188 8月 15 09:50 dump.rdb-rw-rw-r-- 1 quellanan quellanan 58810 8月 14 09:18 redis.conf-rw-rw-r-- 1 quellanan quellanan 58882 8月 14 09:16 redis_slaveof1.conf-rw-r--r-- 1 quellanan quellanan 58882 8月 15 09:11 redis_slaveof2.conf 权限问题我感觉还是挺大的，因为我们一般都是远程到服务器上操作，所以用户权限很多都需要注意。 2、还有一个也是发现master_link_status:down，但是并不是用户权限问题导致的，查看一下防火墙的状态，将防火墙关闭了试试。 123ufw status 查看防火墙状态ufw enable 开启防火墙ufw disable 关闭防火墙 3、在主节点插入数据的时候出现问题 12127.0.0.1:6379&gt; set a 1qaz(error) MISCONF Redis is configured to save RDB snapshots, but it is currently not able to persist on disk. Commands that may modify the data set are disabled, because this instance is configured to report errors during writes if RDB snapshotting fails (stop-writes-on-bgsave-error option). Please check the Redis logs for details about the RDB error. 执行这个 123456127.0.0.1:6379&gt; config set stop-writes-on-bgsave-error noOK127.0.0.1:6379&gt; set a 123456OK127.0.0.1:6379&gt; get a"123456" 主从复制的原理上面以及搭建了一个主从复制的样例，是一主两从的，那是怎么redis是怎么具体实现的呢？在将原理之前，先来看看主从复制的几个概念。启动master后 123456789101112131415161718192021127.0.0.1:6379&gt; info server# Serverredis_version:4.0.9redis_git_sha1:00000000redis_git_dirty:0redis_build_id:514e9a11b2a67dfcredis_mode:standaloneos:Linux 5.0.0-23-generic x86_64arch_bits:64multiplexing_api:epollatomicvar_api:atomic-builtingcc_version:7.4.0process_id:19688run_id:136de716105e54294144003a881ba29cdfbccfb2tcp_port:6379uptime_in_seconds:4515uptime_in_days:0hz:10lru_clock:5556386executable:/usr/local/redis/etc/redis-serverconfig_file:/usr/local/redis/etc/redis.conf 这个run_id 就是redis服务的唯一标识，重启redis服务号，这个run_id 会改变，多个redis客户端连接到同一个服务端，其run_id 是一样的，也就是说run_id 指的是服务端的id 1234567891011121314127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=192.168.252.53,port=6389,state=online,offset=5541,lag=1slave1:ip=192.168.252.53,port=6399,state=online,offset=5541,lag=0master_replid:f0c89aa8040dfe869de82ee623a1212240456d76master_replid2:0000000000000000000000000000000000000000master_repl_offset:5541second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:5541 其中repl_backlog_size 复制缓存区大小，默认大小为1M，如果mater_repl_offset在这个范围内，就看是部分复制，否则就开始全量复制。 全量复制先看下图，图画的不是很好见谅1、首先slave会向 master发送一个 psync 命令，因为是第一次，所以不知道run_id 和offset，所以传过来-1表示全量复制2、 master在接收到psync 后，将run_id 和offset 发送给slave，slave存储起来3、master进行bgsave生成rdb ,并将rdb 文件发送给slave4、在bgsave 和send rdb 的过程中可能会产生write 的数据，那么就会把数据存到repl_back_buffer 中 并将buffer发送给slave .5、slave 会清空就数据，然后加载rdb和buffer 将数据存储起来。 部分复制既然是部分复制，那就是slave已经知道了master的run_id 和offset ,所以发送psync 命令带上这两个参数，master 就知道这是部分复制，然后通过偏移量将需要复制的数据发送给slave。 总结主从复制的过程中既用到了全量复制也用到了部分复制，二者是相互配合使用的。看下面的流程图：还有一点需要注意的是，如果master 重启了，那么它的run_id发生了改变，那么依赖它的slave都会进行一次全量复制后在进行部分复制。 哨兵模式哨兵模式介绍在将哨兵模式之前，先来说说主从复制的缺点吧。如果主节点出了问题，那么主节点不在提供服务，需要手动的将从节点切换成主节点。 所以这个时候哨兵模式就出现啦，当主节出现故障时，Redis Sentinel会自动的发现主节点的故障并转移，并通知应用方，实现高可用。 下面是Redis官方文档对于哨兵功能的描述：1、监控（Monitoring）：哨兵会不断地检查主节点和从节点是否运作正常。2、自动故障转移（Automatic failover）：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。3、配置提供者（Configuration provider）：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。4、通知（Notification）：哨兵可以将故障转移的结果发送给客户端。 哨兵模式的结构拓扑图大概如下，也是照书上画的哈哈大意就是1、每一个哨兵节点会监听其他的哨兵节点以及master 和所有的slave2、所有哨兵节点会定期的ping 主节点，监控是否正常3、如果认为主节点出现故障的哨兵数量达到阙zhi，就判定主节点死掉，主节点就会客观下线4、主节点客观下线后，哨兵节点通过选举模式在 slave 中选择出一个升级为主节点5、其他的salve 指向新的主节点6、原来的master 变成 slave ，并且指向新的主节点 引用官方哨兵模式处理流程 每个Sentinel（哨兵）进程以每秒钟一次的频率向整个集群中的Master主服务器，Slave从服务器以及其他Sentinel（哨兵）进程发送一个 PING 命令。●如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel（哨兵）进程标记为主观下线（SDOWN）。●如果一个Master主服务器被标记为主观下线（SDOWN），则正在监视这个Master主服务器的所有 Sentinel（哨兵）进程要以每秒一次的频率确认Master主服务器的确进入了主观下线状态。●当有足够数量的 Sentinel（哨兵）进程（大于等于配置文件指定的值）在指定的时间范围内确认Master主服务器进入了主观下线状态（SDOWN）， 则Master主服务器会被标记为客观下线（ODOWN）。●在一般情况下， 每个 Sentinel（哨兵）进程会以每 10 秒一次的频率向集群中的所有Master主服务器、Slave从服务器发送 INFO 命令。●当Master主服务器被 Sentinel（哨兵）进程标记为客观下线（ODOWN）时，Sentinel（哨兵）进程向下线的 Master主服务器的所有 Slave从服务器发送 INFO 命令的频率会从 10 秒一次改为每秒一次。●若没有足够数量的 Sentinel（哨兵）进程同意 Master主服务器下线， Master主服务器的客观下线状态就会被移除。若 Master主服务器重新向 Sentinel（哨兵）进程发送 PING 命令返回有效回复，Master主服务器的主观下线状态就会被移除。 哨兵模式部署1、首先到我们redis安装目录下，发现有sentinel.conf ，我们把它移到我们自己定义的文件夹中，和redis.conf 放在一起。1mv sentinel.conf /usr/local/redis/etc/ 2、修改sentinel.conf文件 123456789port 26379dir /usr/local/redis/etc 这里默认的是“/tmp”，如果你没有这个目录的权限就需要换啦，换一个你有权限的目录，不然后果自负哈哈，我就是从坑里爬起来的sentinel monitor mymaster 192.168.252.53 6379 2sentinel auth-pass mymaster 123456设置监控的主节点，2是一个阈值，代表有两台或两台以上哨兵判断主节点redis不通的话就认定这个节点有问题，实行故障转移。daemonize yes 后台启动logfile "/usr/local/redis/logs/redis_sentinel-26379.log" 加上日志 ，不加也无所谓 注意，这个auth-pass 要放在放在monitor 下面，不然会报错配上一些参数说明：3、将sentinel.conf 复制两份，分别为sentinel26389.conf,sentinel26399.conf并修改这个文件中的prot 和logfile 12345port 26389logfile "/usr/local/redis/logs/redis_sentinel-26389.log" port 26399logfile "/usr/local/redis/logs/redis_sentinel-26399.log" 4、启动哨兵 123redis-sentinel /usr/local/redis/etc/sentinel.confredis-sentinel /usr/local/redis/etc/sentinel26389.confredis-sentinel /usr/local/redis/etc/sentinel26399.conf 查看一下，三个哨兵都已经启动了。 5、验证先看看启动日志,，下图所示表明监控了三个节点。如果没有监控到这三个节点，证明没有配置成功。没有配置成功的原因可能是防火墙导致的，关闭调防火墙。还有就是如果redis-server重启过，那在sentinel.conf中生成的pid 和最后的运行添加的几行需要删除掉，下图这些。然后重新运行。 好的，日志看的没有问题，如果不想看日志，我们来这样验证，我们已经启动了三个redis服务，三个哨兵。我们现在把 master 杀死看看是什么情况。 1kill -9 19688 看日志，三个哨兵的监控日志基本上是一样的，下图贴出三个哨兵的日志，我们就看一下第一个哨兵的日志分析一下。看上图，启动哨兵的时候，监控到了master 6379 和两个slave 6389和6399，以及另外两个哨兵，26389和26399.然后sdown master mymaster 192.168.252.53 6379 表示刚刚我们杀死的master服务。这个时候有一个哨兵表示其主观下线，等到odown 达到我们设置的2时，表明有两个哨兵表示其主观下线，那么就认为6379这个master 已经客观下线。然后通过选举，选取26399 这个哨兵为这三个哨兵的领导者(leader)。23699 这个leader 在salve中选择6399转为 master将6389 这个slave 指向新的 master 6399这个时候重启6379 这个redis服务将6379 这个slave指向新的master 6399好，下面我们来看看界面可以看到master已经切换到6399 服务了，现在我们再切换一下，看下面这张图应该很清晰啦 到此为止，哨兵模式就搭建好啦，当 master 挂掉时，会自动的将一个slave 升级成 master 并将其他的 slave 指向新的master ，从新把原来的master启动后，会变成slave 执行新的master 。 总结写到这，其实还有一部分没有写完，但是感觉实在是太长了，就先写这么多吧，还差一个怎么在项目中使用搭建的哨兵模式，也就是集群模式，怎么做到读写分离，实现高可用的。因为前面这些讲的都是在redis数据库上直接操作，那现在部署好了，怎么在项目代码中使用呢，所以下篇接着将在项目中怎么使用redis集群。喜欢的小伙伴可以持续关注啦。 好了，上面都是题外话，下面总结一下这篇文章吧。1、主从复制是什么以及作用。2、怎样部署一个主从复制（案例一主两从）3、怎样部署哨兵模式（三哨兵）其实我感觉如果你通过这篇文章学会了这三点，就够了，其他的看看当了解。 谢谢大家 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[五、redis配置信息以及常用命令]]></title>
    <url>%2F20190808%2F%E4%BA%94%E3%80%81redis%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[前言本来不打算写这篇的，因为网上有很多这种的，最后想想，既然打算做一个redis系列，还是把这一篇补上，刚好这段时间有个同事做了一个redis的基础培训，整理的很好，就拿来借用一下，但是我们实际开发中其实用不了那么多，我们对这些配置和命令有个大概的了解就行，也不用死记硬背的把每个命令和配置记住，当然诸位如果能记住那就更好啦。关于redis的介绍就不多说了，持久化，速度快，单线程，基于内存。 配置文件redis的配置文件是redis.conf。我们上次安装的时候把它放在了/use/local/redis/etc/redis.conf,默认的配置文件应该在安装目录下的src/redis.conf配置文件的内容有很多 Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no 当Redis以守护进程方式运行时，Redis默认会把pid写入/var/run/redis.pid文件，可以通过pidfile指定 pidfile /var/run/redis.pid 指定Redis监听端口，默认端口为6379 port 6379 绑定的主机地址bind 127.0.0.1 当 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 300 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose loglevel verbose 日志记录方式，默认为标准输出，如果配置Redis为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null，如果需要存储日志可以设置具体文件名。 logfile “/home/gdmt/mastercom/redis-4.0.5/bin/log_master.log” 设置数据库的数量，默认数据库为0，可以使用SELECT 命令在连接上指定数据库id databases 16 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合 save Redis默认配置文件中提供了三个条件： save 900 1 save 300 10 save 60 10000 分别表示900秒（15分钟）内有1个更改，300秒（5分钟）内有10个更改以及60秒内有10000个更改。 指定存储至本地数据库时是否压缩数据，默认为yes，Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大rdbcompression yes 指定本地数据库文件名，默认值为dump.rdbdbfilename dump.rdb 指定本地数据库存放目录dir “/home/mastercom/redis-4.0.5/bin” 设置当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步slaveof 当master服务设置了密码保护时，slav服务连接master的密码masterauth 设置Redis连接密码，如果配置了连接密码，客户端在连接Redis时需要通过AUTH 命令提供密码，默认关闭requirepass foobared 设置同一时间最大客户端连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxclients 10000 指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区maxmemory 指定是否在每次更新操作后进行日志记录，Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为noappendonly no 指定更新日志文件名，默认为appendonly.aof appendfilename appendonly.aof 总结一下上面那么多配置，我和大家一样没有都记住，只是了解一个大概，要用的时候能查就行，上面很多都是默认配置，感觉一般要设置的下面这几个 12345daemonize yesport 端口号bind ip slaveof &lt;masterip&gt; &lt;masterport&gt;requirepass foobared 常用命令针对key的命令123456789101112exists(key)：确认一个key是否存在del(key)：删除一个keytype(key)：返回值的类型keys(pattern)：返回满足给定pattern的所有keyrandomkey：随机返回key空间的一个keyrename(oldname, newname)：重命名keydbsize：返回当前数据库中key的数目expire：设定一个key的活动时间（s）ttl：获得一个key的活动时间move(key, dbindex)：移动当前数据库中的key到dbindex数据库flushdb：删除当前选择数据库中的所有key--慎用flushall：删除所有数据库中的所有key--慎用 真正常用的就 12345exists keydel keytype keydbsizeexpire 针对String类型的命令1234567891011121314set(key, value)：给数据库中名称为key的string赋予值valueget(key)：返回数据库中名称为key的string的valuegetset(key, value)：给名称为key的string赋予上一次的valuemget(key1, key2,…, key N)：返回库中多个string的valuesetnx(key, value)：如果key不存在，添加string，名称为key，值为valuesetex(key, time, value)：向库中添加string，设定过期时间timemset(key N, value N)：批量设置多个string的值msetnx(key N, value N)：如果所有名称为key 的string都不存在 就添加incr(key)：名称为key的string增1操作incrby(key, integer)：名称为key的string增加integerdecr(key)：名称为key的string减1操作decrby(key, integer)：名称为key的string减少integerappend(key, value)：名称为key的string的值附加valuesubstr(key, start, end)：返回名称为key的string的value的子串 我认为常用的 123456setget msetmgetincrdecr 针对List类型12345678910111213rpush(key, value)：在名称为key的list尾添加一个值为value的元素lpush(key, value)：在名称为key的list头添加一个值为value的 元素llen(key)：返回名称为key的list的长度lrange(key, start, end)：返回名称为key的list中start至end之间的元素,-1是最后一位的索引ltrim(key, start, end)：截取名称为key的listlindex(key, index)：返回名称为key的list中index位置的元素lset(key, index, value)：给名称为key的list中index位置的元素赋值lrem(key, count, value)：删除count个key的list中值为value的元素lpop(key)：返回并删除名称为key的list中的首元素rpop(key)：返回并删除名称为key的list中的尾元素blpop(key1, key2,… key N, timeout)：lpop命令的block版本。brpop(key1, key2,… key N, timeout)：rpop的block版本。rpoplpush(srckey, dstkey)：返回并删除名称为srckey的list的尾元素，并将该元素添加到名称为dstkey的list的头部 一样我认为常用的,但是感觉list 用的不多 123456rpushlpushrlangllenlpoprpop 针对set类型1234567891011121314sadd(key, member)：向名称为key的set中添加元素membersrem(key, member) ：删除名称为key的set中的元素memberspop(key) ：随机返回并删除名称为key的set中一个元素smove(srckey, dstkey, member) ：移到集合元素scard(key) ：返回名称为key的set的基数sismember(key, member) ：member是否是名称为key的set的元素sinter(key1, key2,…key N) ：求交集sinterstore(dstkey, (keys)) ：求交集并将交集保存到dstkey的集合sunion(key1, (keys)) ：求并集sunionstore(dstkey, (keys)) ：求并集并将并集保存到dstkey的集合sdiff(key1, (keys)) ：求差集sdiffstore(dstkey, (keys)) ：求差集并将差集保存到dstkey的集合smembers(key) ：返回名称为key的set的所有元素srandmember(key) ：随机返回名称为key的set的一个元素 感觉这个是用的最少了，很多都记不住，就知道添加和读取.zset 和set的都用的很少12345saddsmemberssaddzrange 针对Hash类型1234567891011hset(key, field, value)：向名称为key的hash中添加元素fieldhget(key, field)：返回名称为key的hash中field对应的valuehmget(key, (fields))：返回名称为key的hash中field i对应的valuehmset(key, (fields))：向名称为key的hash中添加元素field hincrby(key, field, integer)：将名称为key的hash中field的value增加integerhexists(key, field)：名称为key的hash中是否存在键为field的域hdel(key, field)：删除名称为key的hash中键为field的域hlen(key)：返回名称为key的hash中元素个数hkeys(key)：返回名称为key的hash中所有键hvals(key)：返回名称为key的hash中所有键对应的valuehgetall(key)：返回名称为key的hash中所有的键（field）及其对应的value hash类型用的比较多，特别是对象存储时候，基本上都是用hash 存储的。 1234hsethgethmsethmget 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[四、StringRedisTemplate 和RedisTemlate有什么不同]]></title>
    <url>%2F20190807%2F%E5%9B%9B%E3%80%81StringRedisTemplate%20%E5%92%8CRedisTemlate%E6%9C%89%E4%BB%80%E4%B9%88%E4%B8%8D%E5%90%8C.html</url>
    <content type="text"><![CDATA[前言上一篇文章讲的搭建一个redis+ spring boot 的实例，用到了RedisTemplate，可以成功的访问redis数据库，也可以从中读取数据并显示在页面上，但是呢有瑕疵，那就是其实存在数据库中的Key值是乱码的，类似下面图片这样的。在网上找了一堆的解决办法，看到有StringRedisTemplate 代替RedisTemlate的，所以这边文章就来说说二者到底有什么不同，两者有哪些与缺点，以及在项目中我们如何去使用它。 二者不同先来看看StringRedisTemplate ，为什么先看他，因为它实际上是继承RedisTemplate的，并且源码很简单，只有十几行，所以先来看看它。源码： 12345678910111213141516171819public class StringRedisTemplate extends RedisTemplate&lt;String, String&gt; &#123; public StringRedisTemplate() &#123; this.setKeySerializer(RedisSerializer.string()); this.setValueSerializer(RedisSerializer.string()); this.setHashKeySerializer(RedisSerializer.string()); this.setHashValueSerializer(RedisSerializer.string()); &#125; public StringRedisTemplate(RedisConnectionFactory connectionFactory) &#123; this(); this.setConnectionFactory(connectionFactory); this.afterPropertiesSet(); &#125; protected RedisConnection preProcessConnection(RedisConnection connection, boolean existingConnection) &#123; return new DefaultStringRedisConnection(connection); &#125;&#125; 看源码可以看到，就两个构造方法，构造方法中对key和value 进行序列化，这个序列化是使用RedisSerializer.string()序列化的。看看RedisSerializer.string(）的源码可以发现就是将编码格式设置成了UTF-8再看看带参数的构造函数，多了一个RedisConnectionFactory 参数，这个参数是是在创建连接的时候，设置连接的信息。在网上copy了一个这个方法的实例，可以参考一下：看到这里，大伙差不多就应该知道StringRedisTemplate和RedisTemlate有什么不同了吧。StringRedisTemplate继承了RedisTemlate,但是又仅仅修改了key和values序列化的方式。那就说明StringRedisTemplate和RedisTemlate实际上就是key和values序列化的方式不同啦。那接下来再看看RedisTemlate是怎么序列化的。RedisTemlate的源码就比较多了，我们这里就暂时先看其序列化的：可以看到redisTemplate是使用jdk默认编码格式来序列化的。1new JdkSerializationRedisSerializer(this.classLoader != null ? this.classLoader : this.getClass().getClassLoader()) 所以才出现了文章最开始，使用redisTemplate，存的key值在redis数据库中实际上是乱码的。而StringTemplate不会。 二者优缺关于二者优缺点，我们先来看一个例子：还是上一篇博客的源代码，RedisService层使用的是RedisTemplate，界面上存取，显示都没有问题，这里重点关注一下，getUser()，我这里强转User,在界面上可以正常显示。 1234567891011@Autowired private RedisTemplate redisTemplate; public boolean setUser(User user)&#123; ValueOperations ops=redisTemplate.opsForValue(); ops.set(user.getNickname(),user); return true; &#125; public User getUser(String name)&#123; ValueOperations ops=redisTemplate.opsForValue(); return (User)ops.get(name); &#125; 那我们再使用StringTemplate修改RedisService层 123456789101112@Autowired private StringRedisTemplate stringRedisTemplate; public boolean setUser(User user)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(user.getNickname(),user); return true; &#125; public User getUser(String name)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return (User)ops.get(name); &#125; 再来实行set 和get 就会报错。set 方法报错，说明不能将一个对象直接当做value值传过去，没有进行转换。而RedisTemplate却可以直接把对象当做value值存进去了。因为RedisTemplate在写入和读出的时候都进行了转换。被逼无奈的修改了代码如下；RedisController层 1234567891011121314151617181920212223242526272829@RestControllerpublic class RedisController &#123; @Autowired private RedisService redisService; @RequestMapping("/getUser") public User getUser()&#123; String name="quellan"; return redisService.getUser(name); &#125; @RequestMapping("/setUser") public String setUser()&#123; User user=new User("aa@qq.com","quellan","123456","朱",new Date().getTime()+""); redisService.setUser(user); user.setEmail("bb@qq.com"); redisService.setUserBystringRedisTemplate(user); return "添加成功"; &#125; @RequestMapping("/getUserByStringRedisTemplate") public String getUserByStringRedisTemplate()&#123; String name="quellan"; return redisService.getUserBystringRedisTemplate(name); &#125;&#125; RedisService层 1234567891011121314151617181920212223242526272829303132@Service@Slf4jpublic class RedisService &#123; @Autowired private RedisTemplate redisTemplate; @Autowired private StringRedisTemplate stringRedisTemplate; public boolean setUser(User user)&#123; ValueOperations ops=redisTemplate.opsForValue(); ops.set(user.getNickname(),user); return true; &#125; public User getUser(String name)&#123; ValueOperations ops=redisTemplate.opsForValue(); return (User)ops.get(name); &#125; public boolean setUserBystringRedisTemplate(User user)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); ops.set(user.getNickname(),JSONObject.fromObject(user).toString()); return true; &#125; public String getUserBystringRedisTemplate(String name)&#123; ValueOperations ops=stringRedisTemplate.opsForValue(); return JSONObject.fromObject(ops.get(name)).toString(); &#125;&#125; server层就是分别使用RedisTemplate和StringRedisTemplate对User对象进行存和读的操作。特别注意一下StringRedisTemplate由于直接对象不能存，所以先转成string才能存进去的，读出来的时候，也是string形式返回的，如果读出来想要变成user类还得进一步转换。来看看效果现在。先setUser,往redis中插入两条数据，这里可以看到我们代码中设置的key 是一样的，都是quellan来看看获取结果getUser是使用RedisTemplate来获取的，邮箱是aa来看看getUserByStringRedisTemplate,邮箱是bb这里是不是有说明了一个问题：使用RedisTemplate和StringRedisTemplate是相互独立的，在代码中使用相同的key值进行存储，不会替换，两份都会存在，具体原因还是刚刚提到的，其实他们真实存在redis数据库的key 是不一样的，所以才会独立。我们看看redis数据库。可以发现redis数据库中有两个key值，其中key值为quellan的是使用stringRedisTemplate来来存储的，可以看到邮箱为bb。还有一个乱码的key值使用RedisTemplate存储的，在控制台怎么获取这个key值我暂时也不知道，有知道的小伙伴希望告知一下，嘿嘿。 上面说的redisTemplate 和StringRedisTemplate 是独立的，这个在项目中很容易出现坑的，所以小伙伴们得多多注意，不要存的时候用StringRedisTemplate 读的时候用redisTemplate 或者相反。这样可能回到导致死活读不出数据。 总结上面说了这么多，总结一下吧:1、RedisTemplate和StringRedisTemplate存储是分开存的，也就是代码中相同的key实际上在redis数据库中有两个key.原因是RedisTemplate进行了转换，而StringRedisTemplate直接以代码key值存储了。2、如果我们存一些简单的数据结构，建议使用StringRedisTemplate,因为方便在数据库中查看。如果我们存一些复杂的数据接口，比如对象里面还包含多个对象的，就建议使用RedisTemplate了，系统会帮忙转换，省去我们自己转换的麻烦，上面的代码可以看到直接将取到的value值强转成user都没问题，很方便。3、二者可以配合使用，但是不能混着用。 番外redis控制台中文乱码刚刚我们在控制台 get quellan的时候发现userName 是乱码的。那是因为我们进入的方式不对。需要用 1redis-cli --raw -a password 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[三、Redis在SpringBoot中使用案例]]></title>
    <url>%2F20190803%2F%E4%B8%89%E3%80%81Redis%E5%9C%A8SpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%A1%88%E4%BE%8B.html</url>
    <content type="text"><![CDATA[前言最初的目的就想要在项目中把Redis用起来，然后最近公司的项目全部需要转成springboot，所以现在的项目都是Springboot的，自己刚好也研究下Springboot的。所以才有了下文的案例。 项目结构以及相关配置先创建一个springboot 项目，目录结构大体如下。在pom.xml 加入依赖123456789101112131415161718192021&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Redis使用starter--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--注解日志/get/set--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; 说明一下，第一个依赖starter-web 是创建web应用的依赖。lombok 是我自己添加的一个依赖用来注解日志，属性的get/set方法比较方便，其他的三个依赖就是项目中使用redis的依赖啦，一般项目中想要使用redis引入这三个依赖就可以了。 在application.properties中配置redis 1234567891011121314151617#配置redis# Redis数据库索引（默认为0）spring.redis.database=0 # Redis服务器地址spring.redis.host=192.168.252.53# Redis服务器连接端口spring.redis.port=6379 # Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制） 默认 8spring.redis.lettuce.pool.max-active=8# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1spring.redis.lettuce.pool.max-wait=-1# 连接池中的最大空闲连接 默认 8spring.redis.lettuce.pool.max-idle=8# 连接池中的最小空闲连接 默认 0spring.redis.lettuce.pool.min-idle=0 创建Dao层创建dao 包，创建一个User 类,这里使用了lombok提供的@Getter 和@Setter 非常方便，代码看着也很简洁。 1234567891011121314151617181920212223import lombok.Getter;import lombok.Setter;import java.io.Serializable;@Getter@Setterpublic class User implements Serializable &#123; private static final long serialVersionUID = 1L; private Long id; private String userName; private String password; private String email; private String nickname; private String regTime; public User(String email, String nickname, String password, String userName, String regTime) &#123; super(); this.email = email; this.nickname = nickname; this.password = password; this.userName = userName; this.regTime = regTime; &#125;&#125; 创建Service层创建一个service 包，创建一个RedisService类，代码如下： 12345678910111213141516171819202122import com.zlf.learning.Redis.dao.User;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ValueOperations;import org.springframework.stereotype.Service;@Service@Slf4jpublic class RedisService &#123; @Autowired private RedisTemplate redisTemplate; public boolean setUser(User user)&#123; ValueOperations ops=redisTemplate.opsForValue(); ops.set(user.getNickname(),user); log.info("&#123;&#125;",user.toString()); return true; &#125; public User getUser(String name)&#123; ValueOperations ops=redisTemplate.opsForValue(); return (User) ops.get(name); &#125;&#125; 这里面的代码也非常的清晰，使用到的RedisTemplate ，类似于JdbcTemplate .ValueOperations ops=redisTemplate.opsForValue();就是连接了redis数据库。之后就可以从redis 中获取和添加值啦。 Controller层创建一个controller 包，创建一个RedisController类代码如下： 12345678910111213141516@RestControllerpublic class RedisController &#123; @Autowired private RedisService redisService; @RequestMapping("/getUser") public User getUser()&#123; String name="quellan"; return redisService.getUser(name); &#125; @RequestMapping("/setUser") public String setUser()&#123; User user=new User("aa@qq.com","quellan","123456","朱",new Date().getTime()+""); redisService.setUser(user); return "添加成功"; &#125;&#125; 测试到此为止基础的就已经完全搭建好了，可以测试运行下。启动spring boot项目在redis查一下，发现redis中的key 值并不是我们设置的quellan ,而是一串。这就很难受啦。查了一下，原来是使用的RedisTemplate ，spring-data-redis的RedisTemplate&lt;K, V&gt;模板类在操作redis时默认使用JdkSerializationRedisSerializer来进行序列化.这个具体的放在下一章讲吧，感觉一会讲不完，先跳过哈哈。上面的测试说明项目中已经可以正常使用redis啦。 Session共享按理说到上面就已经差不多，接下来来点骚操作。分布式怎么共享session。简单来说就是一个项目部署了多个，怎么确保一个用户访问不同的项目（用户实际是无感知的，通过Nginx转发，实现负载均衡）时确保session一致。盗一张图来展示一下吧。这张图就是多个Tomcat，那怎么实现session共享呢，就是把session存到redis中，每次去就从redis中取，这样就保证了session共享啦。 那这样是不是每次存session都需要手动存到redis中呢，常理来说当然是的，但是既然是SpringBoot 当然需要不一样啦，只需要增加一个依赖，人家就能帮你自动的加载到redis中。下面来看 增加依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置上面已经配置好了 增加SpringSession 类在controller 包中加一个SpringSession 类，命名可能不太规范，见谅哈 123456789101112131415@RestControllerpublic class SpringSession &#123; @Value("$&#123;server.port&#125;") Integer port; @RequestMapping("/setSession") public String setSession(HttpSession session)&#123; session.setAttribute("key","quellanAn"); return String.valueOf(port); &#125; @RequestMapping("/getSession") public String getSession(HttpSession session)&#123; return session.getAttribute("key")+":"+port; &#125;&#125; 代码很简单，就是session存一个值，get获取。这里可以看到没有任何操作redis数据库的对吧。 测试场景1先运行项目，查看一下 这些都没有什么，我们去redis中看一下，redis中是有session值的。 测试场景2好的，接下来继续，因为上面还看不出来共享session。我们将项目打包成jar包运行，这样我们就可以多个端口运行啦，模拟分布式。 run.bat 中代码： 123title learingPorject8090chcpjava -jar learningproject-1.0.0.jar --server.port=8090 run2.bat 改一下端口号就好了。然后运行jar包，在界面访问 这样就实现session共享啦。 番外再多说一句，设置session的过期时间在启动类中加上注解设置过期时间1分钟1@EnableRedisHttpSession(maxInactiveIntervalInSeconds=60) 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二、设置Redis远程访问]]></title>
    <url>%2F20190802%2F%E4%BA%8C%E3%80%81%E8%AE%BE%E7%BD%AERedis%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE.html</url>
    <content type="text"><![CDATA[前言昨天在Linux服务器上安装了Redis，那我怎么在本地直接连接redis呢，不需要先登录服务器，然后再连接redis的那种。其实最初的问题是我想在项目中连接redis，进行使用，发现总是报连接不上，但是我通过xshell6连到虚拟机，然后连redis是没有问题的。所以才想应该是有什么配置需要修改才行。才有了下面的记录。 修改配置进入redis.conf目录 1vim /usr/local/redis/etc/redis.conf 1、 将bind 127.0.0.1 注释掉2、将protected-mode yes 改成 protected-mode no 3、重启redis服务昨天用到的123456查PIDnetstat -anp|grep 6379kill -9 PIDredis-server /usr/local/redis/etc/redis.conf 测试在本地运行cmd 1redis-cli -h ip -p port - a password 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一、Redis安装]]></title>
    <url>%2F20190801%2F%E4%B8%80%E3%80%81Redis%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[1、前言其实Redis安装教程网上有很多，这里记录下来主要是记录自己的实践流程。之前学习过一些Redis的知识，但是都是朦朦胧胧的，现在Redis技术越来越火。不管多小的项目都会凑一凑热闹，所以了解一下Redis还是很有必要的。所以才有了现在的开篇。从安装开始吧。 2、windows安装软件：链接：https://pan.baidu.com/s/1JzjuFM30AAJd6jkf5pG7XQ提取码：oowy 我使用的是安装版的，下载下来运行，下一步下一步就可以，注意安装路径，并且将路径加入Path 中就可以了。 安装完成后，在服务中就可以找到Redis 服务。如果没有启动就启动，如果启动了，那么就可以直接使用Redis了。 然后在控制台输入redis-cliredis-cli就可以进去Redis啦，进行相关的操作。这里是没有设置密码，使用的是默认的6370端口。上面输入的keys * 表示查询出redis 中所有的key。 3、Linux安装本人装了一个Linux虚拟机，xshell6连接上去的。 3.1 下载解压首先下载资源：最新的应该是4.0.9123wget http://download.redis.io/releases/redis-4.0.9.tar.gztar xzvf redis-4.0.8.tar.gz 3.2 安装1234cd redis-4.0.9/ //进入解压目录make //编译cd src //进入src 目录make install PREFIX=/usr/local/redis //进行安装到usr/local/下，方便部署开机启动 3.3 部署1234#将conf文件放大etc目录下mkdir /usr/local/redis/etcmv redis.conf /usr/local/redis/etc 进入src目录，移动 mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-server到/usr/local/redis/bin/ 1mv mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-rdb redis-cli redis-server /usr/local/redis/bin/ 配置redis为后台启动 1vi /usr/local/redis/etc/redis.conf //将daemonize no 改成daemonize yes 3.4 启动启动服务端：1redis-server /usr/local/redis/etc/redis.conf 启动客户端 1redis-cli 4、设置登录密码刚刚上面也看到了，直接输入 1redis-cli 就直接进去了，这样总感觉不安全，并且我们后面肯定不是通过命令行来访问Redis的，还是需要在项目中使用才行，总会配置Redis的密码的。那怎么设置呢。先来看看我们Redis的密码： 1config get requirepass 发现是没有密码的，现在设置一个，用了get 获取，当然用set设置啦。 1config set requirepass 123456 设置好之后，在想看看自己设置的密码是什么，发现没有权限，哈哈，这就证明你密码设置成功了，现在需要登录密码才能访问数据库。 12auth 123456config get requirepass 但是这样设置的密码有一个问题，那就是把控制台关了，从新进入就会发现密码失效啦，这显然不是我们想要的，原来我们那样设置没有写到conf文件中，是不会重启生效的（如果配置文件中没添加密码 那么redis重启后，密码失效）。 所以我们需要修改redis.conf中的requirepass并重新启动。 杀死Redis服务端1234#找到PIDnetstat -anp|grep 6379kill -9 PID 重启后再进去就发现需要密码啦 也可以这样进入 1redis-cli -p 6379 -a 123456 后续加油♡ 欢迎大家关注个人公众号 “程序员爱酸奶” 分享各种学习资料，包含java，linux，大数据等。资料包含视频文档以及源码，同时分享本人及投递的优质技术博文。 如果大家喜欢记得关注和分享哟❤]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>java</tag>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
